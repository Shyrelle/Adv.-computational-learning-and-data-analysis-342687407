{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOpGoE2T-YXS"
      },
      "source": [
        "# Neural Machine Translation with Attention\n",
        "\n",
        "Advanced Learning Fall 2024.   \n",
        "Last updated: 2025-01-12\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For SUBMISSION:   \n",
        "\n",
        "Please upload the complete and executed `ipynb` to your git repository. Verify that all of your output can be viewed directly from github, and provide a link to that git file below.\n",
        "\n",
        "~~~\n",
        "STUDENT ID: 342687407\n",
        "~~~\n",
        "\n",
        "~~~\n",
        "STUDENT GIT LINK: https://github.com/Shyrelle/Adv.-computational-learning-and-data-analysis-342687407\n",
        "~~~\n",
        "In Addition, don't forget to add your ID to the files, and upload to moodle the html version:    \n",
        "  \n",
        "`PS3_Attention_2024_ID_[342687407].html`   \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PpJdYve9cZa6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eecp2PAf7qJq"
      },
      "source": [
        "In this problem set we are going to jump into the depths of `seq2seq` and `attention` and build a couple of PyTorch translation mechanisms with some  twists.     \n",
        "\n",
        "\n",
        "*   Part 1 consists of a somewhat unorthodox `seq2seq` model for simple arithmetics\n",
        "*   Part 2 consists of an `seq2seq - attention` language translation model. We will use it for Hebrew and English.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "-VpUCez9gOZn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajNDsL5HlZN6"
      },
      "source": [
        "A **seq2seq** model (sequence-to-sequence model) is a type of neural network designed specifically to handle sequences of data. The model converts input sequences into other sequences of data. This makes them particularly useful for tasks involving language, where the input and output are naturally sequences of words.\n",
        "\n",
        "Here's a breakdown of how `seq2seq` models work:\n",
        "\n",
        "* The encoder takes the input sequence, like a sentence in English, and processes it to capture its meaning and context.\n",
        "\n",
        "* information is then passed to the decoder, which uses it to generate the output sequence, like a translation in French.\n",
        "\n",
        "* Attention mechanism (optional): Some `seq2seq` models also incorporate an attention mechanism. This allows the decoder to focus on specific parts of the input sequence that are most relevant to generating the next element in the output sequence.\n",
        "\n",
        "`seq2seq` models are used in many natural language processing (NLP) tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbUDn4FObol7"
      },
      "source": [
        "imports: (feel free to add)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crTe33wcD_Eg"
      },
      "outputs": [],
      "source": [
        "# from __future__ import unicode_literals, print_function, division\n",
        "# from io import open\n",
        "# import unicodedata\n",
        "import re\n",
        "import random\n",
        "import unicodedata\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiwtNgENbx2g"
      },
      "source": [
        "## Part 1: Seq2Seq Arithmetic model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1gWov3Gx67I"
      },
      "source": [
        "**Using RNN `seq2seq` model to \"learn\" simple arithmetics!**\n",
        "\n",
        "> Given the string \"54-7\", the model should return a prediction: \"47\".  \n",
        "> Given the string \"10+20\", the model should return a prediction: \"30\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxo92ZgTy6ED"
      },
      "source": [
        "- Watch Lukas Biewald's short [video](https://youtu.be/MqugtGD605k?si=rAH34ZTJyYDj-XJ1) explaining `seq2seq` models and his toy application (somewhat outdated).\n",
        "- You can find the code for his example [here](https://github.com/lukas/ml-class/blob/master/videos/seq2seq/train.py).    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEu_5YvqFPai"
      },
      "source": [
        "1.1) Using Lukas' code, implement a `seq2seq` network that can learn how to solve **addition AND substraction** of two numbers of maximum length of 4, using the following steps (similar to the example):      \n",
        "\n",
        "* Generate data; X: queries (two numbers), and Y: answers   \n",
        "* One-hot encode X and Y,\n",
        "* Build a `seq2seq` network (with LSTM, RepeatVector, and TimeDistributed layers)\n",
        "* Train the model.\n",
        "* While training, sample from the validation set at random so we can visualize the generated solutions against the true solutions.    \n",
        "\n",
        "Notes:  \n",
        "* The code in the example is quite old and based on Keras. You might have to adapt some of the code to overcome methods/code that is not supported anymore. Hint: for the evaluation part, review the type and format of the \"correct\" output - this will help you fix the unsupported \"model.predict_classes\".\n",
        "* Please use the parameters in the code cell below to train the model.     \n",
        "* Instead of using a `wandb.config` object, please use a simple dictionary instead.   \n",
        "* You don't need to run the model for more than 50 iterations (epochs) to get a gist of what is happening and what the algorithm is doing.\n",
        "* Extra credit if you can implement the network in PyTorch (this is not difficult).    \n",
        "* Extra credit if you are able to significantly improve the model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, TimeDistributed, RepeatVector, Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "class CharacterTable(object):\n",
        "    \"\"\"Given a set of characters:\n",
        "    + Encode them to a one hot integer representation\n",
        "    + Decode the one hot integer representation to their character output\n",
        "    + Decode a vector of probabilities to their character output\n",
        "    \"\"\"\n",
        "    def __init__(self, chars):\n",
        "        \"\"\"Initialize character table.\n",
        "        # Arguments\n",
        "            chars: Characters that can appear in the input.\n",
        "        \"\"\"\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        \"\"\"One hot encode given string C.\n",
        "        # Arguments\n",
        "            num_rows: Number of rows in the returned one hot encoding. This is\n",
        "                used to keep the # of rows for each data the same.\n",
        "        \"\"\"\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "        return ''.join(self.indices_char[x] for x in x)\n",
        "\n",
        "# Parameters for the model and dataset.\n",
        "config = {\n",
        "    'training_size': 50000,\n",
        "    'digits': 4,\n",
        "    'hidden_size': 128,\n",
        "    'batch_size': 128,\n",
        "    'epochs': 50\n",
        "}\n",
        "\n",
        "# Maximum length of input is 'int+int' or 'int-int'. Maximum length of int is DIGITS.\n",
        "maxlen = config['digits'] + 1 + config['digits']\n",
        "\n",
        "# All the numbers, plus sign and space for padding.\n",
        "chars = '0123456789+- '\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "questions = []\n",
        "expected = []\n",
        "seen = set()\n",
        "print('Generating data...')\n",
        "while len(questions) < config['training_size']:\n",
        "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
        "                    for i in range(np.random.randint(1, config['digits'] + 1))))\n",
        "    a, b = f(), f()\n",
        "    op = np.random.choice(['+', '-'])\n",
        "    # Skip any addition/subtraction questions we've already seen\n",
        "    # Also skip any such that x+y == y+x for addition (to reduce redundancy).\n",
        "    key = (a, b, op)\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    # Pad the data with spaces such that it is always MAXLEN.\n",
        "    q = '{}{}{}'.format(a, op, b)\n",
        "    query = q + ' ' * (maxlen - len(q))\n",
        "    ans = str(a + b if op == '+' else a - b)\n",
        "    # Answers can be of maximum size DIGITS + 1.\n",
        "    ans += ' ' * (config['digits'] + 1 - len(ans))\n",
        "\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n",
        "\n",
        "print('Total questions:', len(questions))\n",
        "\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(questions), maxlen, len(chars)), dtype=np.bool_)\n",
        "y = np.zeros((len(questions), config['digits'] + 1, len(chars)), dtype=np.bool_)\n",
        "for i, sentence in enumerate(questions):\n",
        "    x[i] = ctable.encode(sentence, maxlen)\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = ctable.encode(sentence, config['digits'] + 1)\n",
        "\n",
        "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
        "# digits.\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]\n",
        "\n",
        "# Explicitly set apart 10% for validation data that we never train over.\n",
        "split_at = len(x) - len(x) // 10\n",
        "(x_train, x_val) = x[:split_at], x[split_at:]\n",
        "(y_train, y_val) = y[:split_at], y[split_at:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe842o1OPt2n",
        "outputId": "470f5412-0d55-47a2-9e8f-e7cdb38aac6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating data...\n",
            "Total questions: 50000\n",
            "Vectorization...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(config['hidden_size'], input_shape=(maxlen, len(chars))))\n",
        "model.add(RepeatVector(config['digits'] + 1))\n",
        "model.add(LSTM(config['hidden_size'], return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(len(chars), activation='softmax')))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train the model each generation and show predictions against the validation\n",
        "# dataset.\n",
        "for iteration in range(1, config['epochs'] + 1):\n",
        "    print()\n",
        "    print('-' * 50)\n",
        "    print('Iteration', iteration)\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=config['batch_size'],\n",
        "              epochs=1,\n",
        "              validation_data=(x_val, y_val))\n",
        "    # Select 10 samples from the validation set at random so we can visualize\n",
        "    # errors.\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "        preds = model.predict(rowx)\n",
        "        preds = preds.argmax(axis=-1)\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
        "        print('Q', q, end=' ')\n",
        "        print('T', correct, end=' ')\n",
        "        if correct.strip() == guess.strip():\n",
        "            print('☑', end=' ')\n",
        "        else:\n",
        "            print('☒', end=' ')\n",
        "        print(guess)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HyWEVC_XYXYD",
        "outputId": "20efa097-f178-4cc1-dd94-a416c70de2ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating data...\n",
            "Total questions: 50000\n",
            "Vectorization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m72,704\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ repeat_vector_12 (\u001b[38;5;33mRepeatVector\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │         \u001b[38;5;34m131,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_12                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m13\u001b[0m)               │           \u001b[38;5;34m1,677\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">72,704</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ repeat_vector_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_12                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,677</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m205,965\u001b[0m (804.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205,965</span> (804.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m205,965\u001b[0m (804.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205,965</span> (804.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Iteration 1\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.3170 - loss: 1.9967 - val_accuracy: 0.3908 - val_loss: 1.6819\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
            "Q 1753-2    T 1751  ☒ 144  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 484-4409  T -3925 ☒ -4444\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 54+492    T 546   ☒ 104  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 6727+2    T 6729  ☒ 106  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 92-992    T -900  ☒ -188 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 6777-9    T 6768  ☒ 166  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 27+4      T 31    ☒ 11   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 2873-4413 T -1540 ☒ -144 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 5128-268  T 4860  ☒ -124 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 227+4011  T 4238  ☒ 1104 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 2\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4024 - loss: 1.6323 - val_accuracy: 0.4153 - val_loss: 1.5844\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 277+50    T 327   ☒ 151  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 559+3     T 562   ☒ 55   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 2338+0    T 2338  ☒ 221  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 136-8984  T -8848 ☒ -5700\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 5209-46   T 5163  ☒ 5559 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 8-751     T -743  ☒ -877 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 4379-38   T 4341  ☒ 3499 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 9-5369    T -5360 ☒ -5577\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 789+8967  T 9756  ☒ 9877 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 2-3183    T -3181 ☒ -2217\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 3\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4232 - loss: 1.5625 - val_accuracy: 0.4373 - val_loss: 1.5179\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 2+9752    T 9754  ☒ 1999 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 6-0       T 6     ☒ -    \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 8401-6759 T 1642  ☒ 1609 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 33+675    T 708   ☒ 444  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 2999+363  T 3362  ☒ 9094 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 44+25     T 69    ☒ 44   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 8526+422  T 8948  ☒ 1061 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 860-3     T 857   ☒ 766  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 493+3     T 496   ☒ 344  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 7997+423  T 8420  ☒ 9076 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 4\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4460 - loss: 1.4934 - val_accuracy: 0.4686 - val_loss: 1.4450\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 7607-20   T 7587  ☒ 7766 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 3-6210    T -6207 ☒ -2216\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 2+27      T 29    ☒ 23   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 7949+458  T 8407  ☒ 1043 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 32-4005   T -3973 ☒ -2218\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 667+3     T 670   ☒ 666  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 184+85    T 269   ☒ 103  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 805-753   T 52    ☒ 81   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 29+444    T 473   ☒ 450  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 0-389     T -389  ☒ -998 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 5\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4745 - loss: 1.4172 - val_accuracy: 0.4888 - val_loss: 1.3823\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 33+675    T 708   ☒ 636  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 2+3815    T 3817  ☒ 2285 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 6100+9559 T 15659 ☒ 1066 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 353-596   T -243  ☒ -356 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 2-8251    T -8249 ☒ -8217\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 66-415    T -349  ☒ -516 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 9-38      T -29   ☒ -36  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 430-89    T 341   ☒ 48   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 7757+986  T 8743  ☒ 7666 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 3814-38   T 3776  ☒ 3846 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 6\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4994 - loss: 1.3488 - val_accuracy: 0.5126 - val_loss: 1.3090\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 94-23     T 71    ☒ 28   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 494+29    T 523   ☒ 403  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 9-290     T -281  ☒ -290 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 664+737   T 1401  ☒ 1333 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 98+634    T 732   ☒ 733  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 2-70      T -68   ☒ -72  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 7938+6    T 7944  ☒ 8733 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 5+2442    T 2447  ☒ 2225 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 440-69    T 371   ☒ 403  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 539-81    T 458   ☒ 533  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 7\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5281 - loss: 1.2744 - val_accuracy: 0.5395 - val_loss: 1.2412\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 9-769     T -760  ☒ -669 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 3814-38   T 3776  ☒ 3871 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 0-5322    T -5322 ☒ -5318\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 517+7     T 524   ☒ 527  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 5181-8209 T -3028 ☒ -113 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 466-29    T 437   ☒ 455  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 84-83     T 1     ☒ -    \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 9012+370  T 9382  ☒ 1057 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 820+239   T 1059  ☒ 1011 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 43-1248   T -1205 ☒ -148 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 8\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5466 - loss: 1.2159 - val_accuracy: 0.5596 - val_loss: 1.1854\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 6800-3600 T 3200  ☒ 598  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 86-9175   T -9089 ☒ -9199\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 6914+57   T 6971  ☒ 6094 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 96+5      T 101   ☒ 94   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 198-5     T 193   ☒ 198  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 85-76     T 9     ☒ -    \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 5-360     T -355  ☑ -355 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 19+4631   T 4650  ☒ 4678 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 98+209    T 307   ☒ 200  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 2338+0    T 2338  ☒ 2334 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 9\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5657 - loss: 1.1595 - val_accuracy: 0.5696 - val_loss: 1.1437\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 32-751    T -719  ☒ -724 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 8798+119  T 8917  ☒ 8789 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 0-2726    T -2726 ☒ -2767\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 292-97    T 195   ☒ 270  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 0+714     T 714   ☒ 710  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 15+64     T 79    ☒ 72   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 759-62    T 697   ☒ 684  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 1116-7050 T -5934 ☒ -7709\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 8670-62   T 8608  ☒ 7617 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 9-4323    T -4314 ☒ -4214\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 10\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5793 - loss: 1.1209 - val_accuracy: 0.5820 - val_loss: 1.1084\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 686+11    T 697   ☒ 783  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 363+451   T 814   ☒ 701  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 48-818    T -770  ☒ -796 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 8714-911  T 7803  ☒ 8666 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 7+971     T 978   ☒ 976  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 1114-131  T 983   ☒ 103  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 7367-3622 T 3745  ☒ 6166 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 4357+5    T 4362  ☒ 4466 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 3+4685    T 4688  ☑ 4688 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 364+3     T 367   ☒ 361  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 11\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5920 - loss: 1.0844 - val_accuracy: 0.5962 - val_loss: 1.0759\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 9531+945  T 10476 ☒ 10317\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 8799-5    T 8794  ☒ 7807 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 27+3020   T 3047  ☒ 3107 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 321+46    T 367   ☒ 371  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 3+414     T 417   ☒ 419  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 789+8967  T 9756  ☒ 1058 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 7661+8    T 7669  ☒ 7671 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 67+684    T 751   ☒ 740  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 7465-410  T 7055  ☒ 7710 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 7-1473    T -1466 ☒ -1477\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 12\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6043 - loss: 1.0544 - val_accuracy: 0.6000 - val_loss: 1.0610\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 3+994     T 997   ☒ 901  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 79+8669   T 8748  ☒ 8713 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 5342-883  T 4459  ☒ 4320 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 1036+8    T 1044  ☒ 1000 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 547+8     T 555   ☒ 560  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 176+29    T 205   ☒ 303  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 7510-6981 T 529   ☒ -110 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 4315-9063 T -4748 ☒ -4511\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 0+75      T 75    ☑ 75   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 8147+653  T 8800  ☒ 8613 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 13\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6144 - loss: 1.0262 - val_accuracy: 0.6092 - val_loss: 1.0326\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 95-810    T -715  ☒ -766 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 274-5002  T -4728 ☒ -4903\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 5-140     T -135  ☒ -149 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 84+27     T 111   ☒ 110  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Q 4604-961  T 3643  ☒ 3544 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 7997+423  T 8420  ☒ 9300 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 459-1     T 458   ☒ 459  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 791+7539  T 8330  ☒ 7554 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Q 89-2004   T -1915 ☒ -1066\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 44-3      T 41    ☒ 30   \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 14\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6263 - loss: 0.9965 - val_accuracy: 0.6185 - val_loss: 1.0056\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 755-0     T 755   ☒ 753  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 3-74      T -71   ☒ -70  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 925+0     T 925   ☒ 921  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 8497+0    T 8497  ☒ 8490 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 172+8     T 180   ☒ 178  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 1+30      T 31    ☒ 30   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 9735+2    T 9737  ☒ 9735 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 7+3562    T 3569  ☒ 3555 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 8346+2    T 8348  ☒ 8441 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 9513+55   T 9568  ☒ 9515 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6350 - loss: 0.9714 - val_accuracy: 0.6217 - val_loss: 0.9909\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 7152+859  T 8011  ☒ 7366 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 8+367     T 375   ☒ 371  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 7070+6    T 7076  ☒ 7096 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 970-5683  T -4713 ☒ -4577\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 54-749    T -695  ☒ -724 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 287-4623  T -4336 ☒ -4599\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 6196+4    T 6200  ☒ 6166 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 23-131    T -108  ☒ -198 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 28+569    T 597   ☒ 691  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 6-10      T -4    ☒ -    \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 16\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6415 - loss: 0.9550 - val_accuracy: 0.6361 - val_loss: 0.9636\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 1437-419  T 1018  ☒ 123  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 6385-9    T 6376  ☒ 6373 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 6-5985    T -5979 ☒ -5984\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 0+901     T 901   ☑ 901  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 68-245    T -177  ☒ -188 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 5400+9    T 5409  ☒ 5414 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 379+358   T 737   ☒ 801  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 951+502   T 1453  ☒ 1535 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 7032+3    T 7035  ☒ 7021 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Q 5+975     T 980   ☒ 981  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 17\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6500 - loss: 0.9315 - val_accuracy: 0.6405 - val_loss: 0.9475\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 74+9      T 83    ☑ 83   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 96+45     T 141   ☒ 131  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 55-56     T -1    ☑ -1   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 756+418   T 1174  ☒ 1076 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 895-7614  T -6719 ☒ -6567\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 3-5       T -2    ☒ -3   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 632-664   T -32   ☒ -1   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 4045+104  T 4149  ☒ 4175 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 5-4444    T -4439 ☒ -4440\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 505-55    T 450   ☒ 476  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 18\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6563 - loss: 0.9146 - val_accuracy: 0.6480 - val_loss: 0.9277\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 3355-484  T 2871  ☒ 2838 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 179+4     T 183   ☒ 180  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 41-19     T 22    ☒ 23   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 833-346   T 487   ☒ 448  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 6722-50   T 6672  ☒ 6655 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 824-5198  T -4374 ☒ -4557\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 58-4608   T -4550 ☒ -4593\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 2681+67   T 2748  ☒ 2759 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 56-45     T 11    ☒ 1    \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 14-6      T 8     ☒ 1    \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 19\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6643 - loss: 0.8951 - val_accuracy: 0.6476 - val_loss: 0.9184\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 68-285    T -217  ☒ -237 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 493+3     T 496   ☒ 490  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 72-26     T 46    ☒ 49   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 15-309    T -294  ☒ -296 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 74-64     T 10    ☒ 2    \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 47+3      T 50    ☒ 49   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 529+89    T 618   ☒ 611  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 3+4960    T 4963  ☒ 4968 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 9-112     T -103  ☒ -101 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 78-2      T 76    ☒ 74   \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6708 - loss: 0.8782 - val_accuracy: 0.6542 - val_loss: 0.9118\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 3+140     T 143   ☒ 146  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 9577+3    T 9580  ☒ 9577 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 9+585     T 594   ☒ 592  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Q 88+706    T 794   ☒ 896  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Q 970-5683  T -4713 ☒ -4594\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 5+99      T 104   ☒ 103  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 69-77     T -8    ☒ -    \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 3144+64   T 3208  ☒ 3275 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 455+22    T 477   ☒ 471  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 6760-4952 T 1808  ☒ 119  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 21\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6756 - loss: 0.8651 - val_accuracy: 0.6566 - val_loss: 0.9078\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 6+555     T 561   ☑ 561  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 41-6085   T -6044 ☒ -6026\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 4+190     T 194   ☒ 192  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 2-7738    T -7736 ☒ -7731\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 972-6036  T -5064 ☒ -5344\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 6-3602    T -3596 ☒ -3602\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 6087+3962 T 10049 ☒ 10252\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 955+8     T 963   ☒ 960  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 5078+734  T 5812  ☒ 6128 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 78-8      T 70    ☒ 60   \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 22\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6828 - loss: 0.8486 - val_accuracy: 0.6618 - val_loss: 0.8902\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 618+42    T 660   ☒ 661  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 9232+4517 T 13749 ☒ 13357\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 0+452     T 452   ☒ 453  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 4991+3917 T 8908  ☒ 6444 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 45-435    T -390  ☒ -380 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 3532-9    T 3523  ☒ 3535 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 18+92     T 110   ☒ 111  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 7505+6    T 7511  ☒ 7510 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 2155-5    T 2150  ☒ 2152 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 9+9861    T 9870  ☒ 9865 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 23\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6867 - loss: 0.8358 - val_accuracy: 0.6708 - val_loss: 0.8656\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 127-3805  T -3678 ☒ -3789\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 7610+83   T 7693  ☒ 7726 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 21-4293   T -4272 ☒ -4260\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 702+77    T 779   ☒ 781  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 9-17      T -8    ☒ -1   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 4+17      T 21    ☑ 21   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 1600-8023 T -6423 ☒ -7725\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 45-839    T -794  ☒ -706 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 895-7614  T -6719 ☒ -6554\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 7375+2840 T 10215 ☒ 9097 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 24\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6929 - loss: 0.8203 - val_accuracy: 0.6685 - val_loss: 0.8644\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 119-55    T 64    ☒ 149  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 34+2896   T 2930  ☒ 2939 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 564-8998  T -8434 ☒ -8394\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 41+539    T 580   ☒ 599  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 8705+614  T 9319  ☒ 9211 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 4927-2    T 4925  ☒ 4915 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 80-52     T 28    ☒ 31   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 4379+9305 T 13684 ☒ 13711\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 5933+23   T 5956  ☒ 5933 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 1368+3384 T 4752  ☒ 5797 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 25\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6973 - loss: 0.8075 - val_accuracy: 0.6785 - val_loss: 0.8409\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 512+3064  T 3576  ☒ 3755 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 7011+113  T 7124  ☒ 7131 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 321+46    T 367   ☒ 361  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 5265-999  T 4266  ☒ 4466 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 56+9873   T 9929  ☒ 9926 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 6738+86   T 6824  ☒ 6816 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 96+1195   T 1291  ☒ 1204 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 34-9      T 25    ☑ 25   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 5-38      T -33   ☒ -34  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 7532+4945 T 12477 ☒ 12112\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 26\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7029 - loss: 0.7965 - val_accuracy: 0.6817 - val_loss: 0.8307\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 1271+7    T 1278  ☒ 1277 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 8554-37   T 8517  ☒ 8537 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 8+3569    T 3577  ☑ 3577 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 495+8     T 503   ☑ 503  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 72-800    T -728  ☒ -722 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 983-15    T 968   ☒ 975  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 92-622    T -530  ☒ -547 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 3+8630    T 8633  ☒ 8636 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 4-6945    T -6941 ☒ -6943\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 2317+4    T 2321  ☒ 2342 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 27\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7093 - loss: 0.7771 - val_accuracy: 0.6794 - val_loss: 0.8347\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 66-9364   T -9298 ☒ -9269\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 782-491   T 291   ☒ 398  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 2198+0    T 2198  ☒ 2294 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 15-473    T -458  ☒ -469 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 7997+423  T 8420  ☒ 8321 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 206-978   T -772  ☒ -745 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 5521-0    T 5521  ☒ 5520 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 9741+746  T 10487 ☒ 10401\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Q 486+39    T 525   ☒ 528  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 50-5      T 45    ☒ 46   \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 28\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7132 - loss: 0.7677 - val_accuracy: 0.6865 - val_loss: 0.8204\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 6621-9685 T -3064 ☒ -3222\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 8874+177  T 9051  ☒ 9038 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 74+133    T 207   ☒ 295  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 674+6476  T 7150  ☒ 7165 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 497-9951  T -9454 ☒ -9482\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 36+292    T 328   ☒ 325  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 6-98      T -92   ☑ -92  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 79+4860   T 4939  ☒ 4945 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 1445+1605 T 3050  ☒ 5698 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 395+749   T 1144  ☒ 1220 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 29\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7176 - loss: 0.7578 - val_accuracy: 0.6914 - val_loss: 0.8103\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 96-9677   T -9581 ☒ -9599\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 8034-8    T 8026  ☒ 8038 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 1983-420  T 1563  ☒ 1554 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 28-3202   T -3174 ☒ -3190\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 912+94    T 1006  ☒ 1010 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 341+6     T 347   ☒ 348  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 1967-235  T 1732  ☒ 1652 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 349+51    T 400   ☒ 387  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 3-6622    T -6619 ☒ -6614\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 6-233     T -227  ☒ -228 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7208 - loss: 0.7461 - val_accuracy: 0.6905 - val_loss: 0.8044\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 828-7     T 821   ☒ 820  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 621+48    T 669   ☒ 679  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 84-84     T 0     ☒ 1    \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 1983-420  T 1563  ☒ 1555 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 1+847     T 848   ☑ 848  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 53+5884   T 5937  ☒ 5922 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 127-1     T 126   ☒ 125  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 326+5370  T 5696  ☒ 5758 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 454+52    T 506   ☒ 599  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 96+1195   T 1291  ☒ 1265 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 31\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7263 - loss: 0.7323 - val_accuracy: 0.6940 - val_loss: 0.7960\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 484-4409  T -3925 ☒ -3733\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 7979-418  T 7561  ☒ 7500 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 1400-161  T 1239  ☒ 1066 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 7-4488    T -4481 ☑ -4481\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 763-588   T 175   ☒ 18   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 399+79    T 478   ☑ 478  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 82+153    T 235   ☑ 235  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 3966+2248 T 6214  ☒ 5445 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 766+496   T 1262  ☒ 1360 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 792+0     T 792   ☑ 792  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 32\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7304 - loss: 0.7206 - val_accuracy: 0.7012 - val_loss: 0.7773\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 7-71      T -64   ☑ -64  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 1642-47   T 1595  ☒ 1509 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 6+246     T 252   ☑ 252  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 20-97     T -77   ☑ -77  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 3-523     T -520  ☑ -520 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 6121+35   T 6156  ☒ 6247 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 201+9314  T 9515  ☒ 9525 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 451+4     T 455   ☑ 455  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 21+19     T 40    ☒ 30   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 4896+2363 T 7259  ☒ 6445 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 33\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7373 - loss: 0.7045 - val_accuracy: 0.7026 - val_loss: 0.7756\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 668+821   T 1489  ☒ 1481 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 303-54    T 249   ☒ 268  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 6565-875  T 5690  ☒ 5778 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 43+7393   T 7436  ☒ 7410 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 3-45      T -42   ☑ -42  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 14-6364   T -6350 ☒ -6339\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 8-1815    T -1807 ☑ -1807\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 6649+3158 T 9807  ☒ 1059 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 92+70     T 162   ☑ 162  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 5184-4    T 5180  ☒ 5188 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 34\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7405 - loss: 0.6975 - val_accuracy: 0.7030 - val_loss: 0.7698\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 7849+3    T 7852  ☒ 7842 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 197-31    T 166   ☒ 155  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 54-749    T -695  ☒ -606 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 24-5395   T -5371 ☒ -5366\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 1255-9    T 1246  ☒ 1247 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 1781-2990 T -1209 ☒ -1110\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 1-419     T -418  ☑ -418 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 9-1531    T -1522 ☒ -1524\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 1-547     T -546  ☑ -546 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 3+596     T 599   ☒ 590  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 35\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7433 - loss: 0.6881 - val_accuracy: 0.7066 - val_loss: 0.7603\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 724-4762  T -4038 ☒ -4007\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 70-4      T 66    ☒ 67   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 7517+98   T 7615  ☒ 7625 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 7325-34   T 7291  ☒ 7299 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 34+303    T 337   ☒ 329  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 54+140    T 194   ☒ 285  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 5+3769    T 3774  ☒ 3783 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 5094-9    T 5085  ☒ 5092 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 67-48     T 19    ☒ 29   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 346+2560  T 2906  ☒ 2939 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 36\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7491 - loss: 0.6745 - val_accuracy: 0.7099 - val_loss: 0.7545\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 7387+8    T 7395  ☒ 7495 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 816-806   T 10    ☒ -1   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 4021+88   T 4109  ☒ 4110 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 367-952   T -585  ☒ -603 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 311+63    T 374   ☒ 363  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 3-6622    T -6619 ☑ -6619\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 86+9974   T 10060 ☒ 10055\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 37-4      T 33    ☒ 32   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 466-451   T 15    ☒ -7   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 3013-139  T 2874  ☒ 2895 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 37\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7543 - loss: 0.6581 - val_accuracy: 0.7156 - val_loss: 0.7375\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 1120+2    T 1122  ☒ 1123 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 0-662     T -662  ☑ -662 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 11-86     T -75   ☒ -74  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 0+20      T 20    ☑ 20   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Q 3-192     T -189  ☒ -190 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 648-3     T 645   ☒ 643  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 1948-891  T 1057  ☒ 803  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 20-2150   T -2130 ☒ -2162\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 9274-343  T 8931  ☒ 8090 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 3618+4717 T 8335  ☒ 8641 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 38\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7583 - loss: 0.6467 - val_accuracy: 0.7152 - val_loss: 0.7352\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 111+17    T 128   ☒ 129  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 9457+5471 T 14928 ☒ 14111\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 9+9861    T 9870  ☒ 9878 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 84+701    T 785   ☑ 785  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 781-276   T 505   ☒ 598  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 4896+2363 T 7259  ☒ 6044 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 7-842     T -835  ☒ -836 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 40-225    T -185  ☒ -181 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 5851-7    T 5844  ☒ 5848 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 0-351     T -351  ☑ -351 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 39\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7622 - loss: 0.6385 - val_accuracy: 0.7225 - val_loss: 0.7186\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 322+1     T 323   ☑ 323  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 2137-94   T 2043  ☒ 2034 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 611-21    T 590   ☑ 590  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 378+8653  T 9031  ☒ 9909 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 2-770     T -768  ☑ -768 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 99-934    T -835  ☒ -844 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 619-5838  T -5219 ☒ -5263\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 90+48     T 138   ☒ 139  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 953+3     T 956   ☑ 956  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 46+99     T 145   ☒ 144  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 40\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7664 - loss: 0.6237 - val_accuracy: 0.7218 - val_loss: 0.7190\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 74+7204   T 7278  ☒ 7291 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 1494+478  T 1972  ☒ 2021 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 796+7     T 803   ☒ 804  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 340+7812  T 8152  ☒ 8221 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 159+8     T 167   ☒ 166  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 768-2747  T -1979 ☒ -2087\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 6508+9    T 6517  ☒ 6510 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 7997+423  T 8420  ☒ 8222 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 186+35    T 221   ☒ 312  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 104+7075  T 7179  ☒ 7121 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 41\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7723 - loss: 0.6134 - val_accuracy: 0.7270 - val_loss: 0.7077\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 3+21      T 24    ☑ 24   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 3972+1    T 3973  ☒ 3979 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 505-55    T 450   ☒ 459  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 23-115    T -92   ☒ -90  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 4310+7    T 4317  ☒ 4319 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 62+570    T 632   ☒ 625  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 44+41     T 85    ☑ 85   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 28+6      T 34    ☑ 34   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 53-56     T -3    ☒ -5   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 6-5985    T -5979 ☒ -5987\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 42\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7761 - loss: 0.6000 - val_accuracy: 0.7335 - val_loss: 0.6900\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 9-42      T -33   ☒ -34  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 5714-387  T 5327  ☒ 5455 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 2519+478  T 2997  ☒ 2995 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 23+1063   T 1086  ☒ 1079 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 2000+915  T 2915  ☒ 1948 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Q 3+7897    T 7900  ☒ 7901 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 35+83     T 118   ☑ 118  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 16-9      T 7     ☒ 6    \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 1077+9    T 1086  ☒ 1075 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 545+675   T 1220  ☒ 1211 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 43\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7786 - loss: 0.5923 - val_accuracy: 0.7321 - val_loss: 0.6920\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 74-9      T 65    ☑ 65   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 1232+969  T 2201  ☒ 2009 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 61+37     T 98    ☑ 98   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 327+973   T 1300  ☒ 1209 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 80-5975   T -5895 ☒ -5815\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 33+59     T 92    ☑ 92   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 3904-2    T 3902  ☒ 3906 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 540+96    T 636   ☒ 635  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 7887+933  T 8820  ☒ 8750 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 567+50    T 617   ☒ 627  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 44\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7843 - loss: 0.5782 - val_accuracy: 0.7348 - val_loss: 0.6826\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 1-3496    T -3495 ☒ -3494\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 8833-488  T 8345  ☒ 8312 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 6690+6172 T 12862 ☒ 13000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Q 211+2791  T 3002  ☒ 3001 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 1+314     T 315   ☒ 314  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 976-955   T 21    ☒ 1    \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 205-0     T 205   ☑ 205  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 4350-8    T 4342  ☒ 4333 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 928-21    T 907   ☒ 916  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 414-7747  T -7333 ☒ -7319\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 45\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7891 - loss: 0.5711 - val_accuracy: 0.7349 - val_loss: 0.6819\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 6086+7268 T 13354 ☒ 13278\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Q 329+840   T 1169  ☒ 1132 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 17-49     T -32   ☒ -22  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 0-662     T -662  ☑ -662 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 118+8221  T 8339  ☒ 8301 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 405-9281  T -8876 ☒ -8882\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 636+464   T 1100  ☒ 1019 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 3+433     T 436   ☑ 436  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 2710-140  T 2570  ☒ 2531 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 84+47     T 131   ☒ 132  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 46\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7929 - loss: 0.5577 - val_accuracy: 0.7414 - val_loss: 0.6724\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 10+724    T 734   ☑ 734  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 6-4121    T -4115 ☒ -4106\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 7206-9    T 7197  ☒ 7201 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 292-7643  T -7351 ☒ -7344\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 545+675   T 1220  ☒ 1311 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 128+9     T 137   ☑ 137  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 89+6014   T 6103  ☒ 6100 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 1547+47   T 1594  ☒ 1512 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 95-399    T -304  ☒ -306 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 202+6     T 208   ☒ 207  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 47\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7964 - loss: 0.5483 - val_accuracy: 0.7380 - val_loss: 0.6744\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 305+7     T 312   ☒ 311  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 575-29    T 546   ☒ 545  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 735-2     T 733   ☒ 734  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 8976-2    T 8974  ☒ 8985 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 82+5651   T 5733  ☒ 574  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 2-3320    T -3318 ☒ -3320\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 1161+646  T 1807  ☒ 1757 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 563-88    T 475   ☒ 465  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 18+7634   T 7652  ☑ 7652 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 43-268    T -225  ☒ -224 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 48\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8005 - loss: 0.5359 - val_accuracy: 0.7422 - val_loss: 0.6647\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 4604-961  T 3643  ☒ 4329 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 256+489   T 745   ☒ 744  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 91-7446   T -7355 ☒ -7366\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 5065-71   T 4994  ☒ 5976 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 299+23    T 322   ☑ 322  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 8+97      T 105   ☑ 105  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 8-469     T -461  ☒ -460 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 13+33     T 46    ☑ 46   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 528-4     T 524   ☑ 524  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 3319+12   T 3331  ☒ 3320 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 49\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8025 - loss: 0.5297 - val_accuracy: 0.7523 - val_loss: 0.6415\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 156-82    T 74    ☒ 57   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 50-1      T 49    ☑ 49   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 5421-8691 T -3270 ☒ -3222\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 2-770     T -768  ☑ -768 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 7166+3    T 7169  ☒ 7161 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 10-6197   T -6187 ☑ -6187\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 756-99    T 657   ☒ 564  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 63-9043   T -8980 ☒ -8999\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 2552+60   T 2612  ☒ 2613 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 6183+8    T 6191  ☒ 6199 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8067 - loss: 0.5212 - val_accuracy: 0.7536 - val_loss: 0.6348\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 8+480     T 488   ☒ 489  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 6453-694  T 5759  ☒ 5764 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 11-980    T -969  ☒ -970 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Q 775+0     T 775   ☑ 775  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 4722+3    T 4725  ☑ 4725 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Q 731+5096  T 5827  ☒ 5816 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 2532+846  T 3378  ☒ 3377 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Q 4808-31   T 4777  ☒ 4779 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 857-4888  T -4031 ☒ -4100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Q 364+3     T 367   ☑ 367  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXJQqZbEbRup"
      },
      "source": [
        "1.2).\n",
        "\n",
        "a) Do you think this model performs well?  Why or why not?     \n",
        "b) What are its limitations?   \n",
        "c) What would you do to improve it?    \n",
        "d) Can you apply an attention mechanism to this model? Why or why not?   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a)\n",
        "The model shows steady improvement in accuracy during training, reaching approximately 80.67% accuracy on the training set and 75.36% on the validation set after 50 epochs. However, many predictions are incorrect or only partially correct, especially for larger or more complex numbers. Additionally, I noticed that it struggles with subtraction problems involving negative results.\n",
        "\n",
        "b)\n",
        "Sequence-to-Sequence Challenges: The model uses a simple LSTM-based encoder-decoder architecture without attention. This can cause issues, especially with long sequences or complex tasks.\n",
        "Plus, he decoder's predictions depend on prior outputs, which means early mistakes can propagate and make worse predictions.\n",
        "\n",
        "c)\n",
        "I woukd Introduce an attention mechanism (for exemple Luong attention) to allow the model to dynamically focus on relevant parts of the input sequence during decoding. Plus, I would use bidirectional encoder in order to read sequences forward and backward and improve its ability to capture context for both addition and subtraction, especially with longer inputs.\n",
        "\n",
        "d)\n",
        "Yes, an attention mechanism can be applied to this model. Attention mechanisms work well with sequence-to-sequence tasks where the output depends heavily on specific parts of the input. Attention can be integrated into the decoder to dynamically focus on specific time steps in the input sequence when predicting each output step.\n"
      ],
      "metadata": {
        "id": "L5qaqAUiec0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3).  \n",
        "\n",
        "Add attention to the model. Evaluate the performance against the `seq2seq` you trained above. Which one is performing better?"
      ],
      "metadata": {
        "id": "6wvRhhOcgmrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, TimeDistributed, RepeatVector, Dot, Activation, Concatenate\n",
        "\n",
        "class LuongAttentionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(LuongAttentionLayer, self).__init__()\n",
        "\n",
        "    def call(self, decoder_hidden_state, encoder_outputs):\n",
        "        score = Dot(axes=[2, 2])([decoder_hidden_state, encoder_outputs])\n",
        "\n",
        "        attention_weights = Activation('softmax')(score)\n",
        "\n",
        "        context_vector = Dot(axes=[2, 1])([attention_weights, encoder_outputs])\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "config = {\n",
        "    'training_size': 50000,\n",
        "    'digits': 4,\n",
        "    'hidden_size': 128,\n",
        "    'batch_size': 128,\n",
        "    'epochs': 50\n",
        "}\n",
        "\n",
        "maxlen = config['digits'] + 1 + config['digits']\n",
        "chars = '0123456789+- '\n",
        "num_chars = len(chars)\n",
        "\n",
        "encoder_inputs = Input(shape=(maxlen, num_chars), name=\"encoder_inputs\")\n",
        "\n",
        "encoder_lstm = LSTM(config['hidden_size'], return_sequences=True, return_state=True, name=\"encoder_lstm\")\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(config['digits'] + 1, num_chars), name=\"decoder_inputs\")\n",
        "decoder_lstm = LSTM(config['hidden_size'], return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "attention_layer = LuongAttentionLayer()\n",
        "context_vector, attention_weights = attention_layer(decoder_outputs, encoder_outputs)\n",
        "\n",
        "decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
        "\n",
        "output_dense = TimeDistributed(Dense(num_chars, activation=\"softmax\"), name=\"output_dense\")\n",
        "decoder_predictions = output_dense(decoder_combined_context)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_predictions)\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "x_train_decoder = np.zeros((len(x_train), config['digits'] + 1, num_chars), dtype=np.bool_)\n",
        "x_val_decoder = np.zeros((len(x_val), config['digits'] + 1, num_chars), dtype=np.bool_)\n",
        "\n",
        "x_train_decoder[:, 1:, :] = y_train[:, :-1, :]\n",
        "x_train_decoder[:, 0, chars.index(' ')] = 1\n",
        "x_val_decoder[:, 1:, :] = y_val[:, :-1, :]\n",
        "x_val_decoder[:, 0, chars.index(' ')] = 1\n",
        "\n",
        "# Train the model\n",
        "for iteration in range(1, config['epochs'] + 1):\n",
        "    print(f\"\\nIteration {iteration}\")\n",
        "    model.fit(\n",
        "        [x_train, x_train_decoder],\n",
        "        y_train,\n",
        "        batch_size=config['batch_size'],\n",
        "        epochs=1,\n",
        "        validation_data=([x_val, x_val_decoder], y_val),\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "\n",
        "        decoder_input = np.zeros((1, config['digits'] + 1, len(chars)))\n",
        "        decoder_input[:, 0, chars.index(' ')] = 1\n",
        "\n",
        "        preds = model.predict([rowx, decoder_input])\n",
        "        preds = preds.argmax(axis=-1)\n",
        "\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ''.join(ctable.indices_char[idx] for idx in preds[0])\n",
        "\n",
        "        print('Q', q, end=' ')\n",
        "        print('T', correct, end=' ')\n",
        "        if correct.strip() == guess.strip():\n",
        "            print('☑', end=' ')\n",
        "        else:\n",
        "            print('☒', end=' ')\n",
        "        print(guess)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aUKVA0gkeacq",
        "outputId": "789c7024-59ab-4d89-9ee7-0496ac443621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m13\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m13\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m),       │         \u001b[38;5;34m72,704\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │                        │\n",
              "│                           │ \u001b[38;5;34m128\u001b[0m)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m),       │         \u001b[38;5;34m72,704\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],    │\n",
              "│                           │ \u001b[38;5;34m128\u001b[0m)]                  │                │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ luong_attention_layer_3   │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m),       │              \u001b[38;5;34m0\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mLuongAttentionLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m9\u001b[0m)]          │                │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ luong_attention_layer… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ output_dense              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m13\u001b[0m)          │          \u001b[38;5;34m3,341\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)         │                        │                │                        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">72,704</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │                        │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">72,704</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],    │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]                  │                │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ luong_attention_layer_3   │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LuongAttentionLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)]          │                │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ luong_attention_layer… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ output_dense              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,341</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │                        │                │                        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m148,749\u001b[0m (581.05 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">148,749</span> (581.05 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m148,749\u001b[0m (581.05 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">148,749</span> (581.05 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 1\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 60ms/step - accuracy: 0.3412 - loss: 1.9391 - val_accuracy: 0.4297 - val_loss: 1.5793\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step\n",
            "Q 506+0     T 506   ☒ 66   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 3555+64   T 3619  ☒ 5555 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 240-7416  T -7176 ☒ -24  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 493+807   T 1300  ☒ 1004 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 9024+32   T 9056  ☒ 1002 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 673+81    T 754   ☒ 777  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 346+719   T 1065  ☒ 1444 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Q 485-35    T 450   ☒ 544  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 28+30     T 58    ☒ 12   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 6-2491    T -2485 ☒ -164 \n",
            "\n",
            "Iteration 2\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.4359 - loss: 1.5540 - val_accuracy: 0.4504 - val_loss: 1.4879\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 708-6     T 702   ☒ 778  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 9204-4623 T 4581  ☒ 4401 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 518-1     T 517   ☒ 558  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 7+984     T 991   ☒ 888  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 5984+461  T 6445  ☒ 1555 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 1252+4    T 1256  ☒ 222  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 6+236     T 242   ☒ 666  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 447+72    T 519   ☒ 444  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 2-454     T -452  ☒ -44  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 1-4474    T -4473 ☒ -444 \n",
            "\n",
            "Iteration 3\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.4502 - loss: 1.4859 - val_accuracy: 0.4618 - val_loss: 1.4445\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 9709+3    T 9712  ☒ 9999 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 47+714    T 761   ☒ 744  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 70+5423   T 5493  ☒ 5777 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 17-367    T -350  ☒ -61  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 7033-6911 T 122   ☒ -334 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 24+59     T 83    ☒ 54   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 23+1      T 24    ☒ 22   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 5221+1    T 5222  ☒ 2222 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 22-855    T -833  ☒ -22  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 8384+68   T 8452  ☒ 8883 \n",
            "\n",
            "Iteration 4\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 50ms/step - accuracy: 0.4685 - loss: 1.4289 - val_accuracy: 0.4827 - val_loss: 1.3885\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 983-9639  T -8656 ☒ -22  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 478-1392  T -914  ☒ -22  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 6683-823  T 5860  ☒ 6222 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 4+83      T 87    ☒ 83   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 630-64    T 566   ☒ 32   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 2512-3    T 2509  ☒ 222  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Q 3595+317  T 3912  ☒ 3333 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 5-2554    T -2549 ☒ -552 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 3908-544  T 3364  ☒ 3336 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 83+98     T 181   ☒ 113  \n",
            "\n",
            "Iteration 5\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.4917 - loss: 1.3600 - val_accuracy: 0.5121 - val_loss: 1.3117\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 737+9949  T 10686 ☒ 1127 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 8900+95   T 8995  ☒ 9000 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 3342+7    T 3349  ☒ 3338 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 3-3380    T -3377 ☒ -333 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 480+4     T 484   ☒ 440  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 6093-6155 T -62   ☒ -10  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 7872+2859 T 10731 ☒ 1127 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 908-42    T 866   ☒ 900  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 96-2      T 94    ☒ 92   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 77+9216   T 9293  ☒ 1771 \n",
            "\n",
            "Iteration 6\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 55ms/step - accuracy: 0.5193 - loss: 1.2927 - val_accuracy: 0.5395 - val_loss: 1.2339\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 7583-9    T 7574  ☒ 7732 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 18-760    T -742  ☒ -66  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 72+4812   T 4884  ☒ 4222 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 1-65      T -64   ☒ -6   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 312-264   T 48    ☒ -2   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 70+8763   T 8833  ☒ 8782 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Q 743+807   T 1550  ☒ 1233 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 89-819    T -730  ☒ -78  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 46-29     T 17    ☒ 2    \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 8822-74   T 8748  ☒ 8822 \n",
            "\n",
            "Iteration 7\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 52ms/step - accuracy: 0.5469 - loss: 1.2196 - val_accuracy: 0.5661 - val_loss: 1.1680\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 7289+25   T 7314  ☒ 7784 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 51-393    T -342  ☒ -38  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 9482-6    T 9476  ☒ 9944 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 318+9     T 327   ☒ 333  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 1096+608  T 1704  ☒ 1088 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 64+28     T 92    ☒ 11   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Q 58+13     T 71    ☒ 10   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Q 552+478   T 1030  ☒ 123  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Q 562+8030  T 8592  ☒ 1132 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Q 9-9       T 0     ☒ 1    \n",
            "\n",
            "Iteration 8\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 51ms/step - accuracy: 0.5684 - loss: 1.1543 - val_accuracy: 0.5820 - val_loss: 1.1088\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 20+6327   T 6347  ☒ 6666 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 46-2516   T -2470 ☒ -222 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 6014-798  T 5216  ☒ 5666 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 2845+53   T 2898  ☒ 2863 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 850+4705  T 5555  ☒ 1282 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 725-43    T 682   ☒ 764  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 4039+4    T 4043  ☒ 4002 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Q 9-6679    T -6670 ☒ -6666\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 7+58      T 65    ☒ 63   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 68+28     T 96    ☒ 10   \n",
            "\n",
            "Iteration 9\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.5840 - loss: 1.1041 - val_accuracy: 0.6012 - val_loss: 1.0578\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 6648-8    T 6640  ☒ 6664 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 529+807   T 1336  ☒ 1242 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 1+4       T 5     ☑ 5    \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 5404+745  T 6149  ☒ 5152 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 5468+17   T 5485  ☒ 5554 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 0+9706    T 9706  ☒ 9909 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 4+5728    T 5732  ☒ 55527\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 1798+1576 T 3374  ☒ 2519 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 9-9788    T -9779 ☒ -9881\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 2-98      T -96   ☒ -98  \n",
            "\n",
            "Iteration 10\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.6030 - loss: 1.0490 - val_accuracy: 0.6106 - val_loss: 1.0253\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 3959-3252 T 707   ☒ -11  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 38-324    T -286  ☒ -20  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 0-4709    T -4709 ☒ -4777\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 5-8528    T -8523 ☒ -8857\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 928-4784  T -3856 ☒ -5699\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 61-35     T 26    ☒ 2    \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 7244-59   T 7185  ☒ 7227 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 59-283    T -224  ☒ -22  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 7435-612  T 6823  ☒ 7672 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 833+81    T 914   ☒ 902  \n",
            "\n",
            "Iteration 11\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 51ms/step - accuracy: 0.6188 - loss: 1.0097 - val_accuracy: 0.6249 - val_loss: 0.9843\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 7742+36   T 7778  ☒ 7772 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 8155+72   T 8227  ☒ 8297 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Q 238+2     T 240   ☒ 223  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 20+795    T 815   ☒ 801  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 3345+3    T 3348  ☒ 3333 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Q 513-8238  T -7725 ☒ -8777\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 824+1103  T 1927  ☒ 3111 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 2+6637    T 6639  ☒ 6663 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 251+6     T 257   ☒ 223  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 9+151     T 160   ☒ 120  \n",
            "\n",
            "Iteration 12\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.6319 - loss: 0.9716 - val_accuracy: 0.6346 - val_loss: 0.9594\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 728-8     T 720   ☒ 726  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 0+943     T 943   ☒ 9443 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 294+50    T 344   ☒ 315  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 4164-6    T 4158  ☒ 4138 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 47+46     T 93    ☒ 99   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 8782+6804 T 15586 ☒ 1588 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 4770-80   T 4690  ☒ 4657 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Q 4928+7    T 4935  ☒ 4005 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Q 9+781     T 790   ☒ 888  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 319+7566  T 7885  ☒ 8088 \n",
            "\n",
            "Iteration 13\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 51ms/step - accuracy: 0.6437 - loss: 0.9420 - val_accuracy: 0.6435 - val_loss: 0.9306\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 3361+6000 T 9361  ☒ 8212 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 5036-5642 T -606  ☒ -1   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 571+9     T 580   ☒ 550  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 6+767     T 773   ☒ 770  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 4-9147    T -9143 ☒ -9107\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 161+4068  T 4229  ☒ 4235 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 6-725     T -719  ☒ -713 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 685-981   T -296  ☒ -82  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 83-53     T 30    ☒ 35   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 31+475    T 506   ☒ 502  \n",
            "\n",
            "Iteration 14\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 52ms/step - accuracy: 0.6545 - loss: 0.9105 - val_accuracy: 0.6586 - val_loss: 0.9007\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 7+2445    T 2452  ☒ 2451 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 5+702     T 707   ☒ 711  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Q 8+9418    T 9426  ☒ 9440 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 758+17    T 775   ☒ 793  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 93-255    T -162  ☒ -16  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 672+6     T 678   ☒ 667  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 7-99      T -92   ☒ -98  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 48-5758   T -5710 ☒ -5518\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Q 712+5     T 717   ☒ 716  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Q 2703+8    T 2711  ☒ 2226 \n",
            "\n",
            "Iteration 15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.6663 - loss: 0.8826 - val_accuracy: 0.6659 - val_loss: 0.8756\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 85+6515   T 6600  ☒ 6652 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 37+993    T 1030  ☒ 198  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 503-62    T 441   ☒ 455  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 434-7886  T -7452 ☒ -7602\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 7+62      T 69    ☒ 79   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 546+4735  T 5281  ☒ 5070 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 6167-2982 T 3185  ☒ 240  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 400+178   T 578   ☒ 534  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 287-5354  T -5067 ☒ -5385\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Q 8-5762    T -5754 ☒ -5564\n",
            "\n",
            "Iteration 16\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 52ms/step - accuracy: 0.6751 - loss: 0.8594 - val_accuracy: 0.6682 - val_loss: 0.8684\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 1-8116    T -8115 ☒ -8112\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 519+97    T 616   ☒ 604  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Q 6782-2    T 6780  ☒ 6667 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 90+998    T 1088  ☒ 198  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 0+5347    T 5347  ☒ 4544 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Q 42+44     T 86    ☒ 89   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Q 7-1468    T -1461 ☒ -1440\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 87-2983   T -2896 ☒ -2828\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Q 4202-60   T 4142  ☒ 4121 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 89-500    T -411  ☒ -45  \n",
            "\n",
            "Iteration 17\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - accuracy: 0.6827 - loss: 0.8381 - val_accuracy: 0.6761 - val_loss: 0.8452\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 8-83      T -75   ☒ -77  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 71-25     T 46    ☒ 53   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 9974-1    T 9973  ☒ 9987 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 563+361   T 924   ☒ 997  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 186-5224  T -5038 ☒ -5065\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 2-62      T -60   ☒ -61  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 664+1259  T 1923  ☒ 2277 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 8607-5    T 8602  ☒ 8654 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Q 85-831    T -746  ☒ -778 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 40-379    T -339  ☒ -331 \n",
            "\n",
            "Iteration 18\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 50ms/step - accuracy: 0.6918 - loss: 0.8139 - val_accuracy: 0.6802 - val_loss: 0.8283\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 8+7106    T 7114  ☒ 7111 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 5-4046    T -4041 ☒ -4046\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 8077+7592 T 15669 ☒ 1593 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 7-4108    T -4101 ☒ -4002\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 6+642     T 648   ☒ 656  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 425+43    T 468   ☒ 451  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 9-6963    T -6954 ☒ -6668\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 324+9     T 333   ☒ 331  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 3778-279  T 3499  ☒ 3265 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 2843+685  T 3528  ☒ 3636 \n",
            "\n",
            "Iteration 19\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.6985 - loss: 0.7967 - val_accuracy: 0.6922 - val_loss: 0.8059\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 867+948   T 1815  ☒ 187  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 4157+962  T 5119  ☒ 5401 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 429+44    T 473   ☒ 401  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 1+4285    T 4286  ☒ 4229 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 5370+1    T 5371  ☒ 5353 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 384-788   T -404  ☒ -40  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 9-7049    T -7040 ☒ -7001\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 929-4895  T -3966 ☒ -4100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 0-734     T -734  ☒ -733 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 7275-85   T 7190  ☒ 7187 \n",
            "\n",
            "Iteration 20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.7073 - loss: 0.7723 - val_accuracy: 0.6949 - val_loss: 0.7925\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 8-5314    T -5306 ☒ -5410\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 6194-848  T 5346  ☒ 5331 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 0-814     T -814  ☒ -811 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 921-1     T 920   ☒ 921  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 429-329   T 100   ☒ 12   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 889+574   T 1463  ☒ 1533 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 512+23    T 535   ☒ 537  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 86+90     T 176   ☒ 189  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 435-9379  T -8944 ☒ -9888\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 2-876     T -874  ☑ -874 \n",
            "\n",
            "Iteration 21\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 52ms/step - accuracy: 0.7137 - loss: 0.7571 - val_accuracy: 0.7017 - val_loss: 0.7780\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 2-916     T -914  ☒ -919 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 393+47    T 440   ☒ 413  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 3+456     T 459   ☒ 450  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 1-54      T -53   ☒ -54  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 7+317     T 324   ☒ 332  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 9-4085    T -4076 ☒ -4002\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 78-8838   T -8760 ☒ -8887\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Q 9+260     T 269   ☒ 268  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 987-244   T 743   ☒ 892  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 6-725     T -719  ☒ -718 \n",
            "\n",
            "Iteration 22\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.7206 - loss: 0.7393 - val_accuracy: 0.7048 - val_loss: 0.7589\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 917+49    T 966   ☒ 986  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 52-581    T -529  ☒ -515 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 425+43    T 468   ☒ 460  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 164-44    T 120   ☒ 18   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 583+46    T 629   ☒ 620  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 77+812    T 889   ☒ 899  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 9805+7256 T 17061 ☒ 18744\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 937-39    T 898   ☒ 902  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 2845+53   T 2898  ☒ 2310 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 8932-20   T 8912  ☒ 8899 \n",
            "\n",
            "Iteration 23\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 51ms/step - accuracy: 0.7281 - loss: 0.7199 - val_accuracy: 0.7087 - val_loss: 0.7566\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 3536+1    T 3537  ☒ 3544 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 472+5516  T 5988  ☒ 5001 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 18-58     T -40   ☒ -30  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 8601+80   T 8681  ☒ 8687 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 19-67     T -48   ☒ -41  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 4-544     T -540  ☑ -540 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 7853+4    T 7857  ☒ 7776 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 4395+654  T 5049  ☒ 5121 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 918+43    T 961   ☒ 986  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 2373-9390 T -7017 ☒ -7422\n",
            "\n",
            "Iteration 24\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 0.7315 - loss: 0.7049 - val_accuracy: 0.7122 - val_loss: 0.7357\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 2776-89   T 2687  ☒ 2797 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 583+266   T 849   ☒ 891  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 7-237     T -230  ☒ -220 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 9925+4    T 9929  ☒ 9948 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 7-194     T -187  ☒ -18  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 4143+5    T 4148  ☒ 4130 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 506+9     T 515   ☒ 514  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Q 6853+43   T 6896  ☒ 6700 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 63-3853   T -3790 ☒ -3307\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Q 9149+95   T 9244  ☒ 9243 \n",
            "\n",
            "Iteration 25\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.7383 - loss: 0.6908 - val_accuracy: 0.7174 - val_loss: 0.7258\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 779+2461  T 3240  ☒ 3133 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 61-1345   T -1284 ☒ -127 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 7-37      T -30   ☒ -31  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 790+7813  T 8603  ☒ 8688 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 75-1168   T -1093 ☒ -106 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 152-132   T 20    ☒ -5   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 6191-620  T 5571  ☒ 5522 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 3+84      T 87    ☒ 88   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 6967+2013 T 8980  ☒ 9911 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 7498+3    T 7501  ☒ 7443 \n",
            "\n",
            "Iteration 26\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.7436 - loss: 0.6742 - val_accuracy: 0.7204 - val_loss: 0.7171\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 7-825     T -818  ☒ -828 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 883+35    T 918   ☒ 998  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 75-1168   T -1093 ☒ -116 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 9645+7    T 9652  ☒ 9663 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 5+7465    T 7470  ☒ 7760 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 89+6690   T 6779  ☒ 6777 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 48-6      T 42    ☑ 42   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 5209-56   T 5153  ☒ 5148 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 199+69    T 268   ☒ 256  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 17+529    T 546   ☒ 555  \n",
            "\n",
            "Iteration 27\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.7493 - loss: 0.6603 - val_accuracy: 0.7238 - val_loss: 0.7123\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 39-4378   T -4339 ☒ -4445\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 3435-6    T 3429  ☒ 3331 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 229+9527  T 9756  ☒ 98666\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 29-170    T -141  ☒ -12  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Q 3-354     T -351  ☒ -343 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 23-787    T -764  ☒ -762 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 4053-3701 T 352   ☒ 718  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 917+9099  T 10016 ☒ 19999\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 4143+5    T 4148  ☒ 4140 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 0+6905    T 6905  ☒ 6600 \n",
            "\n",
            "Iteration 28\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 52ms/step - accuracy: 0.7522 - loss: 0.6519 - val_accuracy: 0.7344 - val_loss: 0.6885\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 5-8528    T -8523 ☒ -8835\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 1-4818    T -4817 ☒ -4887\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 6322-0    T 6322  ☒ 63322\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 260-2     T 258   ☒ 222  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Q 4+5267    T 5271  ☒ 5552 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 94-76     T 18    ☒ 14   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 8+823     T 831   ☑ 831  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Q 8761+17   T 8778  ☒ 87897\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 617+996   T 1613  ☒ 1657 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 21+0      T 21    ☒ 22   \n",
            "\n",
            "Iteration 29\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.7584 - loss: 0.6362 - val_accuracy: 0.7319 - val_loss: 0.6909\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 480+193   T 673   ☒ 660  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 490-594   T -104  ☒ -5   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 39-86     T -47   ☒ -40  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 163+17    T 180   ☒ 103  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 2+21      T 23    ☑ 23   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 8242+9758 T 18000 ☒ 18790\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 5362-9147 T -3785 ☒ -323 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 3-974     T -971  ☒ -972 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 1921-5900 T -3979 ☒ -4112\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 58-4480   T -4422 ☒ -4415\n",
            "\n",
            "Iteration 30\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 52ms/step - accuracy: 0.7651 - loss: 0.6186 - val_accuracy: 0.7345 - val_loss: 0.6865\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 0-5509    T -5509 ☒ -5550\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 89-60     T 29    ☒ 27   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 90+10     T 100   ☒ 10   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 7+984     T 991   ☒ 993  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 96+3967   T 4063  ☒ 4064 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 881+7     T 888   ☑ 888  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Q 544-57    T 487   ☒ 401  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 4106-8949 T -4843 ☒ -4176\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 6967+2013 T 8980  ☒ 9918 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 7498+3    T 7501  ☒ 7743 \n",
            "\n",
            "Iteration 31\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 61ms/step - accuracy: 0.7703 - loss: 0.6085 - val_accuracy: 0.7400 - val_loss: 0.6672\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 841+36    T 877   ☑ 877  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 404-50    T 354   ☒ 365  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 7387-8    T 7379  ☒ 73744\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 42+5627   T 5669  ☒ 5565 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 1236-83   T 1153  ☒ 111  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 85+6515   T 6600  ☒ 6652 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 4-5965    T -5961 ☒ -5551\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 9470-2275 T 7195  ☒ 6747 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 715+9     T 724   ☒ 723  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 4723+959  T 5682  ☒ 5501 \n",
            "\n",
            "Iteration 32\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 52ms/step - accuracy: 0.7736 - loss: 0.5974 - val_accuracy: 0.7462 - val_loss: 0.6588\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 237+447   T 684   ☒ 699  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 613+834   T 1447  ☒ 1565 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 32-782    T -750  ☒ -757 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 5614-86   T 5528  ☒ 5554 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 487-7548  T -7061 ☒ -6912\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 906+8731  T 9637  ☒ 9877 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 9244-580  T 8664  ☒ 8717 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Q 364+14    T 378   ☑ 378  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 3967+173  T 4140  ☒ 4022 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 541+590   T 1131  ☒ 199  \n",
            "\n",
            "Iteration 33\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - accuracy: 0.7802 - loss: 0.5830 - val_accuracy: 0.7448 - val_loss: 0.6585\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 69+5220   T 5289  ☒ 5320 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 9726-4673 T 5053  ☒ 3111 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 5927+32   T 5959  ☒ 5568 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 6322-0    T 6322  ☒ 63321\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 9939+59   T 9998  ☒ 19994\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 69+202    T 271   ☒ 223  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 0+8       T 8     ☑ 8    \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Q 800-4223  T -3423 ☒ -3421\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Q 22+69     T 91    ☒ 97   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Q 7+170     T 177   ☒ 178  \n",
            "\n",
            "Iteration 34\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.7831 - loss: 0.5751 - val_accuracy: 0.7548 - val_loss: 0.6364\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 89+6690   T 6779  ☒ 6778 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 79+9403   T 9482  ☒ 9412 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 3443+50   T 3493  ☒ 3484 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 537+3214  T 3751  ☒ 3677 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 930+4529  T 5459  ☒ 5632 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 6016-7    T 6009  ☒ 6001 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 3-77      T -74   ☒ -76  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 4109+4546 T 8655  ☒ 8675 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 3+828     T 831   ☒ 830  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 43-4214   T -4171 ☒ -4177\n",
            "\n",
            "Iteration 35\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 55ms/step - accuracy: 0.7885 - loss: 0.5598 - val_accuracy: 0.7584 - val_loss: 0.6287\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "Q 2282+519  T 2801  ☒ 2181 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n",
            "Q 845+8     T 853   ☒ 851  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Q 24-998    T -974  ☒ -987 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "Q 9716+147  T 9863  ☒ 99888\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 691+6     T 697   ☒ 667  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Q 648-36    T 612   ☒ 624  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 7181+5382 T 12563 ☒ 1244 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Q 9965-8    T 9957  ☒ 9977 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
            "Q 54+989    T 1043  ☒ 194  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "Q 5258+79   T 5337  ☒ 5356 \n",
            "\n",
            "Iteration 36\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 70ms/step - accuracy: 0.7940 - loss: 0.5462 - val_accuracy: 0.7638 - val_loss: 0.6124\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 3256+5    T 3261  ☒ 3331 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Q 9444-478  T 8966  ☒ 8911 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 4633+13   T 4646  ☒ 4554 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 3-710     T -707  ☒ -790 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 5591+16   T 5607  ☒ 5561 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 374+5     T 379   ☒ 349  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Q 6+1284    T 1290  ☒ 1221 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 641-33    T 608   ☒ 692  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 0+696     T 696   ☒ 666  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 372+646   T 1018  ☒ 197  \n",
            "\n",
            "Iteration 37\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.7982 - loss: 0.5350 - val_accuracy: 0.7658 - val_loss: 0.6084\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 1+912     T 913   ☒ 912  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 54-29     T 25    ☒ 26   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 743+807   T 1550  ☒ 1564 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 821+10    T 831   ☒ 8322 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 37-485    T -448  ☒ -440 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 1236-83   T 1153  ☒ 119  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 2400-5099 T -2699 ☒ -2021\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 3797-8895 T -5098 ☒ -5109\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 6073+535  T 6608  ☒ 6671 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 32-0      T 32    ☒ 33   \n",
            "\n",
            "Iteration 38\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.8024 - loss: 0.5241 - val_accuracy: 0.7673 - val_loss: 0.6046\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 937-39    T 898   ☒ 897  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 62+509    T 571   ☒ 560  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 101-5988  T -5887 ☒ -5566\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 978-5     T 973   ☒ 987  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 53-18     T 35    ☑ 35   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 8-5606    T -5598 ☒ -5564\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 2455+4    T 2459  ☒ 2460 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 558+336   T 894   ☒ 991  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Q 5-6281    T -6276 ☒ -6263\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 184-70    T 114   ☒ 13   \n",
            "\n",
            "Iteration 39\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 55ms/step - accuracy: 0.8057 - loss: 0.5161 - val_accuracy: 0.7712 - val_loss: 0.5941\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 773-92    T 681   ☒ 674  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 9037-2336 T 6701  ☒ 5722 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 1929-89   T 1840  ☒ 1011 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 968+77    T 1045  ☒ 1854 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Q 84+85     T 169   ☒ 179  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 7+1839    T 1846  ☒ 1106 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 4473+6375 T 10848 ☒ 9901 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 0+5012    T 5012  ☒ 5000 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 6-2491    T -2485 ☒ -2232\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 23+4      T 27    ☒ 20   \n",
            "\n",
            "Iteration 40\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.8126 - loss: 0.4989 - val_accuracy: 0.7743 - val_loss: 0.5879\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 3-852     T -849  ☒ -850 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 846+5     T 851   ☒ 881  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 173-2     T 171   ☒ 170  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 4732-4    T 4728  ☒ 4468 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 28-2636   T -2608 ☒ -2204\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 2282+519  T 2801  ☒ 2091 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 5078-1    T 5077  ☒ 5008 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 8034+954  T 8988  ☒ 9999 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 3116-2    T 3114  ☒ 3122 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 36+2328   T 2364  ☒ 2235 \n",
            "\n",
            "Iteration 41\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.8152 - loss: 0.4912 - val_accuracy: 0.7761 - val_loss: 0.5863\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 6066-4248 T 1818  ☒ 2555 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 352-1340  T -988  ☒ -991 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 8409-48   T 8361  ☒ 8357 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Q 7019-61   T 6958  ☒ 6001 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 690-78    T 612   ☒ 601  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Q 66-60     T 6     ☒ 1    \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 1+572     T 573   ☒ 553  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Q 19+9859   T 9878  ☒ 99887\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Q 5066-7740 T -2674 ☒ -209 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 8443-6626 T 1817  ☒ 218  \n",
            "\n",
            "Iteration 42\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 0.8181 - loss: 0.4817 - val_accuracy: 0.7807 - val_loss: 0.5730\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 2-357     T -355  ☒ -345 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 46+9760   T 9806  ☒ 9899 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 922-2718  T -1796 ☒ -1219\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 728+6     T 734   ☒ 783  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Q 576-931   T -355  ☒ -36  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 62+9133   T 9195  ☒ 9107 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 3+695     T 698   ☒ 699  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 2+48      T 50    ☑ 50   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 9947+8214 T 18161 ☒ 19766\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 3-431     T -428  ☒ -430 \n",
            "\n",
            "Iteration 43\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.8212 - loss: 0.4726 - val_accuracy: 0.7854 - val_loss: 0.5618\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 34+1931   T 1965  ☒ 1206 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 5-4046    T -4041 ☑ -4041\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 319+1     T 320   ☒ 322  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Q 9-6679    T -6670 ☒ -6661\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 2557-669  T 1888  ☒ 1801 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 4-401     T -397  ☒ -302 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 237-2     T 235   ☒ 223  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Q 94+9291   T 9385  ☒ 9997 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Q 78-257    T -179  ☒ -180 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 3-684     T -681  ☒ -666 \n",
            "\n",
            "Iteration 44\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.8289 - loss: 0.4589 - val_accuracy: 0.7842 - val_loss: 0.5603\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 315+29    T 344   ☒ 342  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 917+49    T 966   ☒ 986  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 3102+790  T 3892  ☒ 3411 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 862-815   T 47    ☒ 66   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 253+29    T 282   ☒ 292  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Q 5935+392  T 6327  ☒ 6334 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Q 552+826   T 1378  ☒ 1305 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 9-82      T -73   ☑ -73  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 1409+774  T 2183  ☒ 2108 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 956+9902  T 10858 ☒ 19985\n",
            "\n",
            "Iteration 45\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.8312 - loss: 0.4529 - val_accuracy: 0.7890 - val_loss: 0.5524\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 5731+70   T 5801  ☒ 5620 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 26-5661   T -5635 ☒ -5555\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 703+51    T 754   ☒ 664  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Q 65-280    T -215  ☒ -205 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 8155+72   T 8227  ☒ 8299 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 867-1     T 866   ☒ 8766 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "Q 3-24      T -21   ☑ -21  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Q 633+4     T 637   ☒ 636  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Q 89-569    T -480  ☒ -401 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Q 49-7488   T -7439 ☒ -7431\n",
            "\n",
            "Iteration 46\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - accuracy: 0.8360 - loss: 0.4400 - val_accuracy: 0.7910 - val_loss: 0.5569\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 714-67    T 647   ☒ 646  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Q 929-9917  T -8988 ☒ -9811\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 0+59      T 59    ☒ 590  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 2120-8    T 2112  ☒ 2121 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 806+5902  T 6708  ☒ 6666 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 8653-1771 T 6882  ☒ 6876 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 9-6610    T -6601 ☒ -6661\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 2+6092    T 6094  ☒ 6002 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 7+105     T 112   ☑ 112  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 908+2     T 910   ☒ 999  \n",
            "\n",
            "Iteration 47\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.8403 - loss: 0.4282 - val_accuracy: 0.7945 - val_loss: 0.5352\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 806+5902  T 6708  ☒ 6686 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 6+642     T 648   ☑ 648  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 8904+7    T 8911  ☒ 8899 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Q 18-4      T 14    ☒ 13   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 9995-4    T 9991  ☒ 9999 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Q 8803-58   T 8745  ☒ 8755 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Q 9763+4    T 9767  ☑ 9767 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 812+7657  T 8469  ☒ 8556 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Q 7+317     T 324   ☒ 334  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Q 51-65     T -14   ☒ -1   \n",
            "\n",
            "Iteration 48\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 55ms/step - accuracy: 0.8452 - loss: 0.4151 - val_accuracy: 0.7995 - val_loss: 0.5273\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 261+1     T 262   ☑ 262  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 6-203     T -197  ☒ -10  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 8445-8036 T 409   ☒ 328  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 8+7666    T 7674  ☒ 76743\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 7834-213  T 7621  ☒ 7799 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 7466-7    T 7459  ☒ 7450 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 252+27    T 279   ☑ 279  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 702-3     T 699   ☒ 698  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 43+1326   T 1369  ☒ 1201 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 0+292     T 292   ☒ 222  \n",
            "\n",
            "Iteration 49\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.8451 - loss: 0.4123 - val_accuracy: 0.7999 - val_loss: 0.5266\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 42-61     T -19   ☒ -1   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 9-690     T -681  ☒ -661 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Q 518-50    T 468   ☒ 458  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 346+719   T 1065  ☒ 1924 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Q 7038-3    T 7035  ☒ 7002 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 924-216   T 708   ☒ 642  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 7942-4181 T 3761  ☒ 4237 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 261-7074  T -6813 ☒ -6745\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 1798+1576 T 3374  ☒ 4455 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 16+922    T 938   ☒ 936  \n",
            "\n",
            "Iteration 50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.8511 - loss: 0.3992 - val_accuracy: 0.7983 - val_loss: 0.5271\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Q 224+37    T 261   ☒ 251  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 8242+9758 T 18000 ☒ 18975\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 4216-983  T 3233  ☒ 3121 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Q 5+292     T 297   ☒ 220  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Q 44+381    T 425   ☑ 425  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 1867+25   T 1892  ☒ 1812 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Q 494-21    T 473   ☒ 446  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Q 72-1189   T -1117 ☒ -1119\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Q 2534-6    T 2528  ☒ 2538 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Q 5658-857  T 4801  ☒ 4764 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with attention: the model started with a a lower accuracy compared with the model without attention, however, it showed a consistent improvement in validation accuracy reaching a higher performance level as its interations increased. The accuracy is aroud 85% at iteration 50. The loss is equal to 0.399\n",
        "\n",
        "Model without attention: achieved quicker initial gains accuracy but plateaued sooner. The accuracy is around 80%. The loss is around 0.52."
      ],
      "metadata": {
        "id": "IPzR6IH1iBKq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4)\n",
        "\n",
        "Using any neural network architecture of your liking, build  a model with the aim to beat the best performing model in 1.1 or 1.3. Compare your results in a meaningful way, and add a short explanation to why you think/thought your suggested network is better."
      ],
      "metadata": {
        "id": "AtEJK5IZkk8j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwZKyzoBKl4G"
      },
      "outputs": [],
      "source": [
        "config = {}\n",
        "config[\"training_size\"] = 40000\n",
        "config[\"digits\"] = 4\n",
        "config[\"hidden_size\"] = 128\n",
        "config[\"batch_size\"] = 128\n",
        "config[\"iterations\"] = 50\n",
        "chars = '0123456789-+ '"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6YxgNvo0W_o"
      },
      "source": [
        "SOLUTION:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tensor = torch.tensor(x_train, dtype=torch.float32).to(config['device'])\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(config['device'])\n",
        "x_val_tensor = torch.tensor(x_val, dtype=torch.float32).to(config['device'])\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).to(config['device'])\n",
        "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)"
      ],
      "metadata": {
        "id": "ZgqSSkWUr3gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "config = {\n",
        "    \"training_size\": 40000,\n",
        "    \"digits\": 4,\n",
        "    \"hidden_size\": 128,\n",
        "    \"batch_size\": 128,\n",
        "    \"iterations\": 50,\n",
        "    \"input_size\": len(chars),\n",
        "    \"output_size\": len(chars),\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "}\n",
        "\n",
        "class LuongAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(LuongAttention, self).__init__()\n",
        "        self.attn = nn.Linear(hidden_size + (hidden_size * 2), hidden_size)\n",
        "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
        "\n",
        "    def forward(self, decoder_hidden_step, encoder_outputs):\n",
        "        batch_size, seq_len, _ = encoder_outputs.shape\n",
        "        decoder_hidden_expanded = decoder_hidden_step.expand(-1, seq_len, -1)\n",
        "        combined = torch.cat((decoder_hidden_expanded, encoder_outputs), dim=2)\n",
        "        scores = self.v(torch.tanh(self.attn(combined)))\n",
        "        attn_weights = torch.softmax(scores, dim=1)\n",
        "        context = torch.sum(attn_weights * encoder_outputs, dim=1, keepdim=True)\n",
        "        return context, attn_weights\n",
        "\n",
        "class Seq2SeqWithAttention(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Seq2SeqWithAttention, self).__init__()\n",
        "        self.encoder_embedding = nn.Linear(input_size, hidden_size)\n",
        "        self.decoder_embedding = nn.Linear(input_size, hidden_size)\n",
        "        self.encoder = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n",
        "        self.decoder_init = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.decoder = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, num_layers=1, batch_first=True, bidirectional=False)\n",
        "        self.attention = LuongAttention(hidden_size)\n",
        "        self.fc = nn.Linear(hidden_size * 3, output_size)\n",
        "\n",
        "    def forward(self, encoder_input, decoder_input):\n",
        "        enc_embed = self.encoder_embedding(encoder_input)\n",
        "        encoder_outputs, (hidden, cell) = self.encoder(enc_embed)\n",
        "        hidden = torch.cat((hidden[0], hidden[1]), dim=1)\n",
        "        cell = torch.cat((cell[0], cell[1]), dim=1)\n",
        "        hidden = self.decoder_init(hidden).unsqueeze(0)\n",
        "        cell = self.decoder_init(cell).unsqueeze(0)\n",
        "        dec_embed = self.decoder_embedding(decoder_input)\n",
        "        decoder_outputs, _ = self.decoder(dec_embed, (hidden, cell))\n",
        "        attention_outputs = []\n",
        "        batch_size, seq_len, _ = decoder_outputs.shape\n",
        "        for t in range(seq_len):\n",
        "            decoder_step = decoder_outputs[:, t, :].unsqueeze(1)\n",
        "            context, _ = self.attention(decoder_step, encoder_outputs)\n",
        "            attention_outputs.append(context)\n",
        "        attention_outputs = torch.cat(attention_outputs, dim=1)\n",
        "        combined = torch.cat((decoder_outputs, attention_outputs), dim=-1)\n",
        "        outputs = self.fc(combined)\n",
        "        return outputs\n",
        "\n",
        "model = Seq2SeqWithAttention(\n",
        "    input_size=config[\"input_size\"],\n",
        "    hidden_size=config[\"hidden_size\"],\n",
        "    output_size=config[\"output_size\"]\n",
        ").to(config[\"device\"])\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = config[\"iterations\"]\n",
        "\n",
        "def calculate_sequence_accuracy(logits, targets):\n",
        "    preds = logits.argmax(dim=-1)\n",
        "    tars = targets.argmax(dim=-1)\n",
        "    correct_sequences = (preds == tars).all(dim=1)\n",
        "    accuracy = correct_sequences.float().mean()\n",
        "    return accuracy.item()\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    print(f\"\\nepoch {epoch} ━━━━━━━━━━━━━━━━━━━━━━\")\n",
        "    model.train()\n",
        "    epoch_loss, correct_total, total_count = 0, 0, 0\n",
        "\n",
        "    for encoder_input, decoder_target in train_loader:\n",
        "        encoder_input, decoder_target = encoder_input.to(config[\"device\"]), decoder_target.to(config[\"device\"])\n",
        "        decoder_input = torch.zeros_like(decoder_target)\n",
        "        decoder_input[:, 1:, :] = decoder_target[:, :-1, :]\n",
        "        decoder_input[:, 0, chars.index(' ')] = 1\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(encoder_input, decoder_input)\n",
        "        batch_size, seq_len, vocab = outputs.shape\n",
        "        loss = criterion(\n",
        "            outputs.view(-1, vocab),\n",
        "            decoder_target.argmax(dim=-1).view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        acc = calculate_sequence_accuracy(outputs, decoder_target)\n",
        "        correct_total += acc * batch_size\n",
        "        total_count += batch_size\n",
        "\n",
        "    print(f\"Loss: {epoch_loss:.4f} | Accuracy: {100.0 * correct_total / total_count:.2f}%\")\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(10):\n",
        "            ind = np.random.randint(0, len(x_val))\n",
        "            rowx = x_val_tensor[ind].unsqueeze(0)\n",
        "            rowy = y_val_tensor[ind].unsqueeze(0)\n",
        "            dec_in = torch.zeros((1, config[\"digits\"] + 1, config[\"input_size\"]), dtype=torch.float32).to(config[\"device\"])\n",
        "            dec_in[:, 0, chars.index(' ')] = 1\n",
        "            out = model(rowx, dec_in)\n",
        "            out = out.argmax(dim=-1).cpu().numpy()\n",
        "            q = ctable.decode(rowx.cpu().numpy()[0])\n",
        "            correct = ctable.decode(rowy.cpu().numpy()[0])\n",
        "            guess = ''.join(ctable.indices_char[idx] for idx in out[0])\n",
        "            print(f\"Q {q:<10} T {correct:<10} {'☑' if correct.strip() == guess.strip() else '☒'} {guess}\")\n"
      ],
      "metadata": {
        "id": "GlF7abtLjz06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fffd84c-9f97-49db-fa3e-25a759925a1c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch 1 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 543.3746 | Accuracy: 1.17%\n",
            "Q 771-7      T 764        ☒ 77   \n",
            "Q 1+590      T 591        ☒ 590  \n",
            "Q 87+66      T 153        ☒ 11   \n",
            "Q 98+30      T 128        ☒ 100  \n",
            "Q 7933-4514  T 3419       ☒ 1133 \n",
            "Q 7989+39    T 8028       ☒ 7933 \n",
            "Q 8656-810   T 7846       ☒ 8033 \n",
            "Q 7718+81    T 7799       ☒ 7703 \n",
            "Q 688+672    T 1360       ☒ 123  \n",
            "Q 9957-337   T 9620       ☒ 9033 \n",
            "\n",
            "epoch 2 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 379.4119 | Accuracy: 5.76%\n",
            "Q 1-3339     T -3338      ☒ -339 \n",
            "Q 6426+15    T 6441       ☒ 6438 \n",
            "Q 924+5456   T 6380       ☒ 5511 \n",
            "Q 4920+8350  T 13270      ☒ 1110 \n",
            "Q 22-844     T -822       ☒ --9  \n",
            "Q 14-595     T -581       ☒ -52  \n",
            "Q 34+1833    T 1867       ☒ 1838 \n",
            "Q 2430+30    T 2460       ☒ 2430 \n",
            "Q 0-2648     T -2648      ☒ -644 \n",
            "Q 25-0       T 25         ☑ 25   \n",
            "\n",
            "epoch 3 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 338.2544 | Accuracy: 7.74%\n",
            "Q 490-4400   T -3910      ☒ -200 \n",
            "Q 4+6405     T 6409       ☒ 6408 \n",
            "Q 52+49      T 101        ☒ 12   \n",
            "Q 34-59      T -25        ☒ -    \n",
            "Q 5811-86    T 5725       ☒ 5706 \n",
            "Q 9-775      T -766       ☒ -79  \n",
            "Q 3719+0     T 3719       ☑ 3719 \n",
            "Q 61+482     T 543        ☒ 562  \n",
            "Q 591-159    T 432        ☒ 591  \n",
            "Q 503-7      T 496        ☒ 509  \n",
            "\n",
            "epoch 4 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 299.3760 | Accuracy: 11.24%\n",
            "Q 67+3139    T 3206       ☒ 3127 \n",
            "Q 37-9391    T -9354      ☒ -9356\n",
            "Q 102-519    T -417       ☒ -3   \n",
            "Q 576+210    T 786        ☒ 876  \n",
            "Q 910-7      T 903        ☒ 916  \n",
            "Q 637+5      T 642        ☒ 632  \n",
            "Q 2354-9     T 2345       ☒ 2344 \n",
            "Q 815+665    T 1480       ☒ 1771 \n",
            "Q 60-92      T -32        ☒ -    \n",
            "Q 806+2      T 808        ☒ 806  \n",
            "\n",
            "epoch 5 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 266.1988 | Accuracy: 17.28%\n",
            "Q 56-319     T -263       ☒ -2   \n",
            "Q 7279-14    T 7265       ☒ 7273 \n",
            "Q 77-5       T 72         ☑ 72   \n",
            "Q 4+782      T 786        ☒ 785  \n",
            "Q 3382-82    T 3300       ☒ 3397 \n",
            "Q 2560+409   T 2969       ☒ 2169 \n",
            "Q 88+212     T 300        ☒ 201  \n",
            "Q 0+148      T 148        ☑ 148  \n",
            "Q 196+9335   T 9531       ☒ 9320 \n",
            "Q 26-6       T 20         ☒ 22   \n",
            "\n",
            "epoch 6 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 237.0892 | Accuracy: 24.66%\n",
            "Q 1373+4     T 1377       ☒ 1372 \n",
            "Q 8577+893   T 9470       ☒ 1560 \n",
            "Q 1836+7658  T 9494       ☒ 9113 \n",
            "Q 932-8      T 924        ☒ 914  \n",
            "Q 2126+17    T 2143       ☒ 2130 \n",
            "Q 182-6      T 176        ☒ 174  \n",
            "Q 169+280    T 449        ☒ 379  \n",
            "Q 3856-26    T 3830       ☒ 3811 \n",
            "Q 4+939      T 943        ☒ 9433 \n",
            "Q 1358+356   T 1714       ☒ 1214 \n",
            "\n",
            "epoch 7 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 203.1781 | Accuracy: 33.45%\n",
            "Q 6826-0     T 6826       ☒ 6825 \n",
            "Q 5266-4     T 5262       ☒ 5261 \n",
            "Q 860-2      T 858        ☑ 858  \n",
            "Q 2-6909     T -6907      ☒ -6909\n",
            "Q 5+77       T 82         ☑ 82   \n",
            "Q 11-764     T -753       ☒ --53 \n",
            "Q 4283-4     T 4279       ☒ 4289 \n",
            "Q 5456-453   T 5003       ☒ 4988 \n",
            "Q 6795-125   T 6670       ☒ 6682 \n",
            "Q 1081-7     T 1074       ☒ 107  \n",
            "\n",
            "epoch 8 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 171.6427 | Accuracy: 43.14%\n",
            "Q 552+770    T 1322       ☒ 1212 \n",
            "Q 2775-25    T 2750       ☒ 2752 \n",
            "Q 9282-465   T 8817       ☒ 8877 \n",
            "Q 7601-6     T 7595       ☑ 7595 \n",
            "Q 3078-533   T 2545       ☒ 2512 \n",
            "Q 8855-5897  T 2958       ☒ 2131 \n",
            "Q 61-34      T 27         ☒ 17   \n",
            "Q 364-72     T 292        ☒ 297  \n",
            "Q 74+66      T 140        ☒ 120  \n",
            "Q 20+9       T 29         ☒ 39   \n",
            "\n",
            "epoch 9 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 148.2263 | Accuracy: 50.76%\n",
            "Q 6+6364     T 6370       ☒ 6371 \n",
            "Q 614-0      T 614        ☑ 614  \n",
            "Q 94-34      T 60         ☒ 69   \n",
            "Q 372-9      T 363        ☑ 363  \n",
            "Q 929+19     T 948        ☑ 948  \n",
            "Q 2488+4     T 2492       ☑ 2492 \n",
            "Q 685-7828   T -7143      ☒ -613 \n",
            "Q 9-4590     T -4581      ☑ -4581\n",
            "Q 3833-9286  T -5453      ☒ -216 \n",
            "Q 7313-4240  T 3073       ☒ 112  \n",
            "\n",
            "epoch 10 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 125.6107 | Accuracy: 57.87%\n",
            "Q 8+4882     T 4890       ☑ 4890 \n",
            "Q 9594-8     T 9586       ☑ 9586 \n",
            "Q 3+4700     T 4703       ☑ 4703 \n",
            "Q 993-167    T 826        ☒ 833  \n",
            "Q 1952+247   T 2199       ☑ 2199 \n",
            "Q 159+74     T 233        ☑ 233  \n",
            "Q 80-4152    T -4072      ☒ -412 \n",
            "Q 4+893      T 897        ☒ 896  \n",
            "Q 27+98      T 125        ☒ 124  \n",
            "Q 3856-26    T 3830       ☒ 3839 \n",
            "\n",
            "epoch 11 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 108.7841 | Accuracy: 63.40%\n",
            "Q 642+276    T 918        ☑ 918  \n",
            "Q 8931-7     T 8924       ☒ 8923 \n",
            "Q 56-8       T 48         ☑ 48   \n",
            "Q 9764-42    T 9722       ☒ 9711 \n",
            "Q 3538+708   T 4246       ☑ 4246 \n",
            "Q 5515-47    T 5468       ☒ 5478 \n",
            "Q 1+323      T 324        ☑ 324  \n",
            "Q 9463-6832  T 2631       ☒ 2279 \n",
            "Q 618+93     T 711        ☒ 701  \n",
            "Q 3+64       T 67         ☒ 68   \n",
            "\n",
            "epoch 12 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 94.0577 | Accuracy: 68.30%\n",
            "Q 0-6897     T -6897      ☑ -6897\n",
            "Q 7984-8     T 7976       ☒ 7977 \n",
            "Q 2682+22    T 2704       ☑ 2704 \n",
            "Q 3651+20    T 3671       ☑ 3671 \n",
            "Q 7+4109     T 4116       ☑ 4116 \n",
            "Q 77-294     T -217       ☒ -22  \n",
            "Q 7478-92    T 7386       ☑ 7386 \n",
            "Q 7697+8382  T 16079      ☒ 16179\n",
            "Q 2+28       T 30         ☒ 20   \n",
            "Q 1+5655     T 5656       ☒ 5655 \n",
            "\n",
            "epoch 13 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 84.2741 | Accuracy: 71.22%\n",
            "Q 1424-400   T 1024       ☒ 1144 \n",
            "Q 162-81     T 81         ☒ 71   \n",
            "Q 5-4685     T -4680      ☒ -4681\n",
            "Q 9480-501   T 8979       ☒ 8879 \n",
            "Q 81+1906    T 1987       ☑ 1987 \n",
            "Q 37-264     T -227       ☒ --1  \n",
            "Q 786-462    T 324        ☑ 324  \n",
            "Q 27-46      T -19        ☒ -    \n",
            "Q 92-989     T -897       ☒ -87  \n",
            "Q 15-484     T -469       ☒ --79 \n",
            "\n",
            "epoch 14 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 75.5069 | Accuracy: 73.77%\n",
            "Q 35+6444    T 6479       ☒ 6478 \n",
            "Q 37-795     T -758       ☑ -758 \n",
            "Q 1+323      T 324        ☑ 324  \n",
            "Q 2250-4     T 2246       ☑ 2246 \n",
            "Q 7509+2     T 7511       ☑ 7511 \n",
            "Q 73+9       T 82         ☑ 82   \n",
            "Q 66+6881    T 6947       ☒ 7947 \n",
            "Q 476-7007   T -6531      ☒ -5521\n",
            "Q 6595+61    T 6656       ☑ 6656 \n",
            "Q 174-40     T 134        ☑ 134  \n",
            "\n",
            "epoch 15 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 67.3891 | Accuracy: 76.62%\n",
            "Q 846+16     T 862        ☑ 862  \n",
            "Q 2+9680     T 9682       ☑ 9682 \n",
            "Q 978+123    T 1101       ☑ 1101 \n",
            "Q 130-6876   T -6746      ☒ -6756\n",
            "Q 5835+9927  T 15762      ☒ 15821\n",
            "Q 22-6576    T -6554      ☒ -6544\n",
            "Q 66+153     T 219        ☑ 219  \n",
            "Q 16-26      T -10        ☒ -    \n",
            "Q 398+12     T 410        ☑ 410  \n",
            "Q 88-13      T 75         ☑ 75   \n",
            "\n",
            "epoch 16 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 60.1782 | Accuracy: 79.06%\n",
            "Q 5+397      T 402        ☑ 402  \n",
            "Q 120-8698   T -8578      ☒ -8688\n",
            "Q 93-12      T 81         ☑ 81   \n",
            "Q 5+703      T 708        ☑ 708  \n",
            "Q 98-7392    T -7294      ☒ -7204\n",
            "Q 8935+7348  T 16283      ☒ 16213\n",
            "Q 978+86     T 1064       ☒ 174  \n",
            "Q 9196-0     T 9196       ☑ 9196 \n",
            "Q 854+12     T 866        ☑ 866  \n",
            "Q 675+260    T 935        ☑ 935  \n",
            "\n",
            "epoch 17 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 54.9991 | Accuracy: 80.84%\n",
            "Q 9980-464   T 9516       ☒ 9744 \n",
            "Q 952-967    T -15        ☒ -5   \n",
            "Q 4305-467   T 3838       ☒ 3868 \n",
            "Q 165-997    T -832       ☒ -732 \n",
            "Q 5611-69    T 5542       ☑ 5542 \n",
            "Q 9-884      T -875       ☑ -875 \n",
            "Q 791+0      T 791        ☑ 791  \n",
            "Q 1+8508     T 8509       ☒ 8519 \n",
            "Q 3577+0     T 3577       ☑ 3577 \n",
            "Q 597-81     T 516        ☑ 516  \n",
            "\n",
            "epoch 18 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 48.6303 | Accuracy: 83.05%\n",
            "Q 52+6334    T 6386       ☒ 6396 \n",
            "Q 5215-2554  T 2661       ☑ 2661 \n",
            "Q 0-732      T -732       ☑ -732 \n",
            "Q 781-94     T 687        ☑ 687  \n",
            "Q 5-8123     T -8118      ☒ -810 \n",
            "Q 1595-5442  T -3847      ☒ --778\n",
            "Q 818-78     T 740        ☒ 730  \n",
            "Q 0-108      T -108       ☒ -18  \n",
            "Q 76-72      T 4          ☒ 5    \n",
            "Q 7505+36    T 7541       ☑ 7541 \n",
            "\n",
            "epoch 19 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 44.7300 | Accuracy: 84.13%\n",
            "Q 3008-7     T 3001       ☑ 3001 \n",
            "Q 664+6418   T 7082       ☒ 7091 \n",
            "Q 4301+2     T 4303       ☑ 4303 \n",
            "Q 1+3545     T 3546       ☑ 3546 \n",
            "Q 938-1      T 937        ☑ 937  \n",
            "Q 51+969     T 1020       ☒ 120  \n",
            "Q 54-35      T 19         ☒ 29   \n",
            "Q 651+140    T 791        ☒ 701  \n",
            "Q 0-2638     T -2638      ☑ -2638\n",
            "Q 74+49      T 123        ☑ 123  \n",
            "\n",
            "epoch 20 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 41.3699 | Accuracy: 85.55%\n",
            "Q 4323+389   T 4712       ☒ 4612 \n",
            "Q 3907-7716  T -3809      ☒ -509 \n",
            "Q 966+999    T 1965       ☑ 1965 \n",
            "Q 185+2      T 187        ☑ 187  \n",
            "Q 4417-72    T 4345       ☒ 4344 \n",
            "Q 50+2771    T 2821       ☑ 2821 \n",
            "Q 0-959      T -959       ☑ -959 \n",
            "Q 463-3448   T -2985      ☒ -105 \n",
            "Q 61-7040    T -6979      ☒ -699 \n",
            "Q 83+2530    T 2613       ☒ 2513 \n",
            "\n",
            "epoch 21 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 40.2880 | Accuracy: 85.42%\n",
            "Q 364-72     T 292        ☑ 292  \n",
            "Q 9+813      T 822        ☑ 822  \n",
            "Q 6611-6     T 6605       ☑ 6605 \n",
            "Q 8722+4     T 8726       ☑ 8726 \n",
            "Q 953-64     T 889        ☑ 889  \n",
            "Q 8-261      T -253       ☒ -22  \n",
            "Q 2824-26    T 2798       ☑ 2798 \n",
            "Q 8+947      T 955        ☑ 955  \n",
            "Q 9-5755     T -5746      ☑ -5746\n",
            "Q 57-83      T -26        ☒ -4   \n",
            "\n",
            "epoch 22 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 35.5629 | Accuracy: 87.48%\n",
            "Q 367+2125   T 2492       ☒ 2592 \n",
            "Q 978+86     T 1064       ☒ 1844 \n",
            "Q 32-16      T 16         ☑ 16   \n",
            "Q 715-267    T 448        ☒ 358  \n",
            "Q 2419-3     T 2416       ☑ 2416 \n",
            "Q 231+80     T 311        ☑ 311  \n",
            "Q 21-98      T -77        ☒ -7   \n",
            "Q 5+831      T 836        ☑ 836  \n",
            "Q 811-9038   T -8227      ☒ -827 \n",
            "Q 7-8368     T -8361      ☑ -8361\n",
            "\n",
            "epoch 23 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 32.0579 | Accuracy: 88.83%\n",
            "Q 4303+6     T 4309       ☑ 4309 \n",
            "Q 609+77     T 686        ☑ 686  \n",
            "Q 10+8726    T 8736       ☑ 8736 \n",
            "Q 749+30     T 779        ☑ 779  \n",
            "Q 3-9787     T -9784      ☒ --784\n",
            "Q 558+19     T 577        ☑ 577  \n",
            "Q 780-421    T 359        ☑ 359  \n",
            "Q 11-764     T -753       ☑ -753 \n",
            "Q 66-157     T -91        ☒ -9   \n",
            "Q 5053+82    T 5135       ☑ 5135 \n",
            "\n",
            "epoch 24 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 33.3889 | Accuracy: 87.77%\n",
            "Q 398-3372   T -2974      ☒ -1084\n",
            "Q 7784+5723  T 13507      ☒ 14807\n",
            "Q 9-1338     T -1329      ☒ -132 \n",
            "Q 8975+0     T 8975       ☑ 8975 \n",
            "Q 6492+2817  T 9309       ☒ 9128 \n",
            "Q 8694-408   T 8286       ☒ 8276 \n",
            "Q 266+5      T 271        ☑ 271  \n",
            "Q 107-70     T 37         ☒ 27   \n",
            "Q 3627-5721  T -2094      ☒ -104 \n",
            "Q 7533-91    T 7442       ☑ 7442 \n",
            "\n",
            "epoch 25 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 25.0613 | Accuracy: 91.53%\n",
            "Q 967-5      T 962        ☑ 962  \n",
            "Q 67-74      T -7         ☒ -    \n",
            "Q 6115-8     T 6107       ☑ 6107 \n",
            "Q 6760+5     T 6765       ☑ 6765 \n",
            "Q 63-3162    T -3099      ☒ -301 \n",
            "Q 7-6329     T -6322      ☒ -6312\n",
            "Q 6684-6     T 6678       ☑ 6678 \n",
            "Q 939+9      T 948        ☑ 948  \n",
            "Q 521+25     T 546        ☑ 546  \n",
            "Q 8-74       T -66        ☒ --6  \n",
            "\n",
            "epoch 26 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 25.9759 | Accuracy: 90.82%\n",
            "Q 113-66     T 47         ☒ 57   \n",
            "Q 24-79      T -55        ☒ -45  \n",
            "Q 476-7007   T -6531      ☒ -4531\n",
            "Q 46+148     T 194        ☑ 194  \n",
            "Q 4+35       T 39         ☑ 39   \n",
            "Q 549-3      T 546        ☑ 546  \n",
            "Q 1630-6853  T -5223      ☒ -310 \n",
            "Q 840-265    T 575        ☑ 575  \n",
            "Q 74-66      T 8          ☑ 8    \n",
            "Q 536+8483   T 9019       ☒ 9219 \n",
            "\n",
            "epoch 27 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 26.2346 | Accuracy: 90.81%\n",
            "Q 3191+264   T 3455       ☑ 3455 \n",
            "Q 1041+4375  T 5416       ☑ 5416 \n",
            "Q 107+96     T 203        ☑ 203  \n",
            "Q 3022-2     T 3020       ☑ 3020 \n",
            "Q 8725+83    T 8808       ☑ 8808 \n",
            "Q 0+16       T 16         ☑ 16   \n",
            "Q 94+77      T 171        ☒ 161  \n",
            "Q 585+810    T 1395       ☒ 1485 \n",
            "Q 694-2279   T -1585      ☒ -365 \n",
            "Q 8+7106     T 7114       ☑ 7114 \n",
            "\n",
            "epoch 28 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 31.5483 | Accuracy: 88.48%\n",
            "Q 987-6668   T -5681      ☒ -3890\n",
            "Q 985-7314   T -6329      ☒ -3389\n",
            "Q 58-7       T 51         ☑ 51   \n",
            "Q 902+68     T 970        ☑ 970  \n",
            "Q 613+8196   T 8809       ☒ 8829 \n",
            "Q 206-134    T 72         ☒ -2   \n",
            "Q 3964+4     T 3968       ☑ 3968 \n",
            "Q 61+9770    T 9831       ☑ 9831 \n",
            "Q 6339+634   T 6973       ☑ 6973 \n",
            "Q 647+85     T 732        ☑ 732  \n",
            "\n",
            "epoch 29 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 19.4741 | Accuracy: 93.63%\n",
            "Q 3925+6511  T 10436      ☒ 1336 \n",
            "Q 29-8565    T -8536      ☑ -8536\n",
            "Q 749+2      T 751        ☑ 751  \n",
            "Q 2614+2207  T 4821       ☑ 4821 \n",
            "Q 213-66     T 147        ☒ 157  \n",
            "Q 1+3754     T 3755       ☑ 3755 \n",
            "Q 79+2       T 81         ☑ 81   \n",
            "Q 3975+5     T 3980       ☑ 3980 \n",
            "Q 3065-4552  T -1487      ☒ -377 \n",
            "Q 76-6802    T -6726      ☑ -6726\n",
            "\n",
            "epoch 30 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 17.9618 | Accuracy: 94.00%\n",
            "Q 60-8841    T -8781      ☒ -8881\n",
            "Q 33+23      T 56         ☑ 56   \n",
            "Q 9051-15    T 9036       ☒ 9034 \n",
            "Q 778-887    T -109       ☒ -1   \n",
            "Q 17-592     T -575       ☒ --75 \n",
            "Q 94-311     T -217       ☒ -07  \n",
            "Q 0+994      T 994        ☑ 994  \n",
            "Q 994+6301   T 7295       ☑ 7295 \n",
            "Q 103-8508   T -8405      ☒ --305\n",
            "Q 445-1573   T -1128      ☒ -139 \n",
            "\n",
            "epoch 31 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 21.3955 | Accuracy: 92.25%\n",
            "Q 677-180    T 497        ☒ 587  \n",
            "Q 36-18      T 18         ☑ 18   \n",
            "Q 93-323     T -230       ☒ -19  \n",
            "Q 7-12       T -5         ☒ -    \n",
            "Q 9511-1     T 9510       ☑ 9510 \n",
            "Q 7-2819     T -2812      ☒ -191 \n",
            "Q 45-7043    T -6998      ☑ -6998\n",
            "Q 561-84     T 477        ☑ 477  \n",
            "Q 76+4049    T 4125       ☑ 4125 \n",
            "Q 76+4049    T 4125       ☑ 4125 \n",
            "\n",
            "epoch 32 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 22.4805 | Accuracy: 91.77%\n",
            "Q 1-5514     T -5513      ☒ -5413\n",
            "Q 18-8376    T -8358      ☑ -8358\n",
            "Q 2646+7     T 2653       ☑ 2653 \n",
            "Q 849+0      T 849        ☑ 849  \n",
            "Q 8+6013     T 6021       ☑ 6021 \n",
            "Q 8+5643     T 5651       ☑ 5651 \n",
            "Q 783-8      T 775        ☑ 775  \n",
            "Q 52-83      T -31        ☒ -1   \n",
            "Q 754+2      T 756        ☑ 756  \n",
            "Q 99+76      T 175        ☑ 175  \n",
            "\n",
            "epoch 33 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 24.6075 | Accuracy: 91.48%\n",
            "Q 41+38      T 79         ☑ 79   \n",
            "Q 54-7659    T -7605      ☑ -7605\n",
            "Q 1395+4     T 1399       ☑ 1399 \n",
            "Q 50+4       T 54         ☑ 54   \n",
            "Q 609+77     T 686        ☑ 686  \n",
            "Q 7478-92    T 7386       ☑ 7386 \n",
            "Q 560-68     T 492        ☑ 492  \n",
            "Q 169-1      T 168        ☑ 168  \n",
            "Q 8752-167   T 8585       ☑ 8585 \n",
            "Q 2947-17    T 2930       ☑ 2930 \n",
            "\n",
            "epoch 34 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 12.3507 | Accuracy: 96.54%\n",
            "Q 5038+268   T 5306       ☒ 5396 \n",
            "Q 526-66     T 460        ☒ 450  \n",
            "Q 64-45      T 19         ☑ 19   \n",
            "Q 626+5069   T 5695       ☑ 5695 \n",
            "Q 0+847      T 847        ☑ 847  \n",
            "Q 4184-41    T 4143       ☑ 4143 \n",
            "Q 975+976    T 1951       ☒ 1941 \n",
            "Q 5+49       T 54         ☑ 54   \n",
            "Q 5725+9866  T 15591      ☒ 15681\n",
            "Q 6684+23    T 6707       ☑ 6707 \n",
            "\n",
            "epoch 35 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 15.7677 | Accuracy: 94.80%\n",
            "Q 358-718    T -360       ☒ -30  \n",
            "Q 9+242      T 251        ☑ 251  \n",
            "Q 4-3524     T -3520      ☑ -3520\n",
            "Q 263-6      T 257        ☑ 257  \n",
            "Q 8656-810   T 7846       ☒ 7856 \n",
            "Q 59-6005    T -5946      ☒ --33 \n",
            "Q 33-570     T -537       ☒ --37 \n",
            "Q 62-869     T -807       ☒ --97 \n",
            "Q 8+234      T 242        ☑ 242  \n",
            "Q 95+1266    T 1361       ☒ 1261 \n",
            "\n",
            "epoch 36 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 17.8073 | Accuracy: 93.60%\n",
            "Q 3505-1     T 3504       ☑ 3504 \n",
            "Q 3+7025     T 7028       ☑ 7028 \n",
            "Q 92+9       T 101        ☒ 111  \n",
            "Q 620+4      T 624        ☑ 624  \n",
            "Q 380+5161   T 5541       ☒ 5531 \n",
            "Q 6+263      T 269        ☑ 269  \n",
            "Q 872-438    T 434        ☒ 444  \n",
            "Q 987-73     T 914        ☑ 914  \n",
            "Q 3134+619   T 3753       ☑ 3753 \n",
            "Q 92-989     T -897       ☒ -888 \n",
            "\n",
            "epoch 37 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 14.7984 | Accuracy: 94.84%\n",
            "Q 5-5964     T -5959      ☑ -5959\n",
            "Q 9446-723   T 8723       ☑ 8723 \n",
            "Q 813+4      T 817        ☑ 817  \n",
            "Q 606-89     T 517        ☑ 517  \n",
            "Q 3+415      T 418        ☑ 418  \n",
            "Q 9957-337   T 9620       ☒ 9621 \n",
            "Q 8609+3546  T 12155      ☒ 12145\n",
            "Q 4023+91    T 4114       ☑ 4114 \n",
            "Q 475-5      T 470        ☑ 470  \n",
            "Q 88+114     T 202        ☑ 202  \n",
            "\n",
            "epoch 38 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 11.2606 | Accuracy: 96.46%\n",
            "Q 9915-8     T 9907       ☑ 9907 \n",
            "Q 9243-26    T 9217       ☑ 9217 \n",
            "Q 4436-4     T 4432       ☑ 4432 \n",
            "Q 7618-4779  T 2839       ☒ 2749 \n",
            "Q 44-16      T 28         ☑ 28   \n",
            "Q 5+8324     T 8329       ☑ 8329 \n",
            "Q 436+73     T 509        ☑ 509  \n",
            "Q 3457+288   T 3745       ☑ 3745 \n",
            "Q 643+865    T 1508       ☒ 1498 \n",
            "Q 9127-8     T 9119       ☑ 9119 \n",
            "\n",
            "epoch 39 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 11.2524 | Accuracy: 96.29%\n",
            "Q 9+656      T 665        ☑ 665  \n",
            "Q 85+78      T 163        ☑ 163  \n",
            "Q 675+260    T 935        ☑ 935  \n",
            "Q 2405-2887  T -482       ☒ -19  \n",
            "Q 93-4407    T -4314      ☒ -332 \n",
            "Q 453-2087   T -1634      ☒ --54 \n",
            "Q 626-31     T 595        ☒ 585  \n",
            "Q 60+6184    T 6244       ☑ 6244 \n",
            "Q 375+61     T 436        ☑ 436  \n",
            "Q 917-8136   T -7219      ☒ -820 \n",
            "\n",
            "epoch 40 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 18.5337 | Accuracy: 93.07%\n",
            "Q 0+5437     T 5437       ☑ 5437 \n",
            "Q 8497+4593  T 13090      ☒ 12999\n",
            "Q 7441+86    T 7527       ☑ 7527 \n",
            "Q 5379+11    T 5390       ☑ 5390 \n",
            "Q 7178-2709  T 4469       ☒ 3468 \n",
            "Q 516+7111   T 7627       ☒ 7637 \n",
            "Q 79-23      T 56         ☑ 56   \n",
            "Q 37-7739    T -7702      ☒ -7712\n",
            "Q 63-3162    T -3099      ☒ -3199\n",
            "Q 923+991    T 1914       ☑ 1914 \n",
            "\n",
            "epoch 41 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 14.2884 | Accuracy: 94.84%\n",
            "Q 96-987     T -891       ☒ -99  \n",
            "Q 5+7868     T 7873       ☑ 7873 \n",
            "Q 8+767      T 775        ☑ 775  \n",
            "Q 398+12     T 410        ☑ 410  \n",
            "Q 6-966      T -960       ☑ -960 \n",
            "Q 8111-419   T 7692       ☒ 7792 \n",
            "Q 3199+334   T 3533       ☑ 3533 \n",
            "Q 271-93     T 178        ☑ 178  \n",
            "Q 70-390     T -320       ☒ -20  \n",
            "Q 531-8871   T -8340      ☒ -8430\n",
            "\n",
            "epoch 42 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 10.8801 | Accuracy: 96.48%\n",
            "Q 22-748     T -726       ☒ --26 \n",
            "Q 897+10     T 907        ☑ 907  \n",
            "Q 601-41     T 560        ☒ 550  \n",
            "Q 331-470    T -139       ☒ -39  \n",
            "Q 4-8256     T -8252      ☒ --252\n",
            "Q 92-2820    T -2728      ☒ -292 \n",
            "Q 9+66       T 75         ☑ 75   \n",
            "Q 20+314     T 334        ☑ 334  \n",
            "Q 2-80       T -78        ☑ -78  \n",
            "Q 185+8024   T 8209       ☒ 8109 \n",
            "\n",
            "epoch 43 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 12.0837 | Accuracy: 95.92%\n",
            "Q 9-479      T -470       ☒ --70 \n",
            "Q 50-6499    T -6449      ☒ -6349\n",
            "Q 738-96     T 642        ☑ 642  \n",
            "Q 5792-576   T 5216       ☑ 5216 \n",
            "Q 7014+98    T 7112       ☑ 7112 \n",
            "Q 6-689      T -683       ☒ --93 \n",
            "Q 790-59     T 731        ☑ 731  \n",
            "Q 9+9817     T 9826       ☑ 9826 \n",
            "Q 81-4       T 77         ☑ 77   \n",
            "Q 6977-17    T 6960       ☑ 6960 \n",
            "\n",
            "epoch 44 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 19.4419 | Accuracy: 92.66%\n",
            "Q 1-28       T -27        ☒ -17  \n",
            "Q 613+8196   T 8809       ☑ 8809 \n",
            "Q 4-7970     T -7966      ☑ -7966\n",
            "Q 3+57       T 60         ☑ 60   \n",
            "Q 2+28       T 30         ☒ 20   \n",
            "Q 699+66     T 765        ☑ 765  \n",
            "Q 5593+86    T 5679       ☑ 5679 \n",
            "Q 1-76       T -75        ☒ --5  \n",
            "Q 7341+9     T 7350       ☑ 7350 \n",
            "Q 8502-8     T 8494       ☑ 8494 \n",
            "\n",
            "epoch 45 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 11.8859 | Accuracy: 95.98%\n",
            "Q 8788+8582  T 17370      ☒ 16360\n",
            "Q 256+1      T 257        ☑ 257  \n",
            "Q 28+1041    T 1069       ☑ 1069 \n",
            "Q 1-26       T -25        ☒ -15  \n",
            "Q 231-998    T -767       ☒ -677 \n",
            "Q 134-52     T 82         ☑ 82   \n",
            "Q 459-86     T 373        ☑ 373  \n",
            "Q 673+7      T 680        ☑ 680  \n",
            "Q 66+48      T 114        ☒ 133  \n",
            "Q 62+3       T 65         ☑ 65   \n",
            "\n",
            "epoch 46 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 6.2618 | Accuracy: 98.64%\n",
            "Q 93+1       T 94         ☑ 94   \n",
            "Q 59-80      T -21        ☒ -1   \n",
            "Q 1875-1     T 1874       ☑ 1874 \n",
            "Q 819+6920   T 7739       ☒ 7839 \n",
            "Q 34-103     T -69        ☒ -0   \n",
            "Q 8536+158   T 8694       ☒ 8684 \n",
            "Q 678-1      T 677        ☑ 677  \n",
            "Q 529-327    T 202        ☑ 202  \n",
            "Q 2342+427   T 2769       ☑ 2769 \n",
            "Q 5365-6     T 5359       ☑ 5359 \n",
            "\n",
            "epoch 47 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 8.9748 | Accuracy: 97.60%\n",
            "Q 4+6821     T 6825       ☑ 6825 \n",
            "Q 3+4700     T 4703       ☑ 4703 \n",
            "Q 846+16     T 862        ☑ 862  \n",
            "Q 8-2649     T -2641      ☒ -2621\n",
            "Q 9-5755     T -5746      ☑ -5746\n",
            "Q 107-70     T 37         ☑ 37   \n",
            "Q 3-7526     T -7523      ☑ -7523\n",
            "Q 2+7140     T 7142       ☑ 7142 \n",
            "Q 295+9      T 304        ☑ 304  \n",
            "Q 174-9      T 165        ☑ 165  \n",
            "\n",
            "epoch 48 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 26.5958 | Accuracy: 90.18%\n",
            "Q 85-578     T -493       ☒ -38  \n",
            "Q 4+35       T 39         ☑ 39   \n",
            "Q 236+2350   T 2586       ☒ 2596 \n",
            "Q 25+373     T 398        ☑ 398  \n",
            "Q 2105+7994  T 10099      ☒ 1100 \n",
            "Q 499+446    T 945        ☒ 935  \n",
            "Q 1835-79    T 1756       ☑ 1756 \n",
            "Q 3+95       T 98         ☑ 98   \n",
            "Q 66-69      T -3         ☒ -    \n",
            "Q 309+105    T 414        ☑ 414  \n",
            "\n",
            "epoch 49 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 6.4358 | Accuracy: 98.58%\n",
            "Q 897+2      T 899        ☑ 899  \n",
            "Q 22+9926    T 9948       ☒ 9928 \n",
            "Q 3151-6     T 3145       ☑ 3145 \n",
            "Q 2+46       T 48         ☑ 48   \n",
            "Q 1+4172     T 4173       ☑ 4173 \n",
            "Q 56+4627    T 4683       ☑ 4683 \n",
            "Q 5518+4     T 5522       ☑ 5522 \n",
            "Q 67-61      T 6          ☑ 6    \n",
            "Q 3+3851     T 3854       ☑ 3854 \n",
            "Q 113-8049   T -7936      ☒ --846\n",
            "\n",
            "epoch 50 ━━━━━━━━━━━━━━━━━━━━━━\n",
            "Loss: 4.1093 | Accuracy: 99.47%\n",
            "Q 8+387      T 395        ☑ 395  \n",
            "Q 7948+8     T 7956       ☑ 7956 \n",
            "Q 218+492    T 710        ☑ 710  \n",
            "Q 72-6541    T -6469      ☒ --469\n",
            "Q 8308-7     T 8301       ☑ 8301 \n",
            "Q 665-74     T 591        ☑ 591  \n",
            "Q 5370-99    T 5271       ☑ 5271 \n",
            "Q 390+1      T 391        ☑ 391  \n",
            "Q 9656-51    T 9605       ☑ 9605 \n",
            "Q 8-5902     T -5894      ☒ --884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Pytorch network reaches an accurary of 97% at the last epoch compared to 85% in the prevvious network which is a significant improvment.\n",
        "\n",
        "I thought using PyTorch Model in bidirectional LSTM for the encoder, capturing forward and backward context. the PyTorch model’s bidirectional LSTM and attention help it improve the performence the TensorFlow model in terms of both final accuracy and training speed."
      ],
      "metadata": {
        "id": "VTbESaYmuB83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "voVYROYNlO49"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-d0eIM6FeaM"
      },
      "source": [
        "## Part 2: A language translation model with attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80jhFbWPMW_a"
      },
      "source": [
        "In this part of the problem set we are going to implement a translation with a Sequence to Sequence Network and Attention model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgL38lJGTYaF"
      },
      "source": [
        "0) Please go over the NLP From Scratch: Translation with a Sequence to Sequence Network and Attention [tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html). This attention model is very similar to what was learned in class (Luong), but a bit different. What are the main differences between  Badahnau and Luong attention mechanisms?    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bahdanau attention computes attention scores using a feed-forward neural network that combines the decoder's hidden state and the encoder's outputs. In contrast, Luong attention, referred to as multiplicative attention, calculates attention scores by taking the dot product between the decoder's hidden state and the encoder's outputs. This difference in computation leads to Bahdanau attention being more flexible but computationally intensive, while Luong attention is more efficient but may be less effective in capturing complex alignments.\n"
      ],
      "metadata": {
        "id": "VEWnKqHKj_Un"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.a) Using `!wget`, `!unzip` , download and extract the [hebrew-english](https://www.manythings.org/anki/) sentence pairs text file to the Colab `content/`  folder (or local folder if not using Colab).\n",
        "1.b) The `heb.txt` must be parsed and cleaned (see tutorial for requirements or change the code as you see fit).   \n"
      ],
      "metadata": {
        "id": "KBX873GJlDl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o /content/heb-eng.zip -d /content/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxhW574uXa7-",
        "outputId": "70fa60e9-fe74-4d3d-d8ae-5516fa1d0539"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/heb-eng.zip\n",
            "  inflating: /content/_about.txt     \n",
            "  inflating: /content/heb.txt        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.a) Use the tutorial example to build  and train a Hebrew to English translation model with attention (using the parameters in the code cell below). Apply the same `eng_prefixes` filter to limit the train/test data.   \n",
        "2.b) Evaluate your trained model randomly on 20 sentences.  \n",
        "2.c) Show the attention plot for 5 random sentences.  \n"
      ],
      "metadata": {
        "id": "AvIIlNvPlGWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "svpj1iR8oQKS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the following parameters:\n",
        "MAX_LENGTH = 10\n",
        "hidden_size = 128\n",
        "epochs = 50"
      ],
      "metadata": {
        "id": "pumbtRhtwPdq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n"
      ],
      "metadata": {
        "id": "iejSckXJuMZb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    \"\"\"Normalize the sentences by removing metadata and cleaning text.\"\"\"\n",
        "    s = re.sub(r\"CC-BY.*\", \"\", s)  # Remove metadata starting with \"CC-BY\"\n",
        "    s = s.strip()\n",
        "    s = re.sub(r\"[^a-zA-Zא-ת\\s]\", \"\", s)  # Keep letters and spaces only\n",
        "    return s.lower().strip()\n"
      ],
      "metadata": {
        "id": "dQdOT5e3wXyR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('heb.txt', encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')[:2]] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    \"\"\"Filter sentence pairs by length and prefixes.\"\"\"\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "           len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    \"\"\"Apply filtering to all pairs.\"\"\"\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "\n",
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(f\"Read {len(pairs)} sentence pairs\")\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(f\"Trimmed to {len(pairs)} sentence pairs\")\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "UiY1B3rVwYoZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "id": "oszZzp_JwbQ8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'heb', True)\n",
        "print(random.choice(pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2FciIxhwh8H",
        "outputId": "d6690603-2125-486b-da07-cbf5ab8c1553"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 128133 sentence pairs\n",
            "Trimmed to 1713 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "heb 2103\n",
            "eng 1278\n",
            "['הוא סופר בעל דמיון רב', 'he is a very imaginative writer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "KXLCygsNwisU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
        "\n",
        "    def forward_step(self, input, hidden):\n",
        "        output = self.embedding(input)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output)\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "83LNwqTzwlYS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded =  self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights"
      ],
      "metadata": {
        "id": "tRc13pMPnbjw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "def get_dataloader(batch_size):\n",
        "\n",
        "    global SOS_token, EOS_token\n",
        "    SOS_token = 0\n",
        "    EOS_token = 1\n",
        "\n",
        "    input_lang, output_lang, pairs = prepareData('eng', 'heb', True)\n",
        "\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = indexesFromSentence(input_lang, inp)\n",
        "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return input_lang, output_lang, train_dataloader"
      ],
      "metadata": {
        "id": "ZWPcVYtXtIBe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "5frETvrgtJAe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "tcXTG0bStP6t"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "FA39GI-3tQ2-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "metadata": {
        "id": "Q1tv9hHEtTXl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])\n",
        "    return decoded_words, decoder_attn"
      ],
      "metadata": {
        "id": "Pc9ymclmtW3p"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder, decoder, n=20):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "metadata": {
        "id": "I9x-mFHstc7s"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhunYZem0xmR",
        "outputId": "b0281dae-229a-4ea4-de52-19f993bdd58c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 128133 sentence pairs\n",
            "Trimmed to 1713 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "heb 2103\n",
            "eng 1278\n",
            "0m 6s (- 1m 41s) (5 6%) 2.4874\n",
            "0m 13s (- 1m 31s) (10 12%) 1.5531\n",
            "0m 18s (- 1m 21s) (15 18%) 1.0885\n",
            "0m 25s (- 1m 15s) (20 25%) 0.7715\n",
            "0m 30s (- 1m 7s) (25 31%) 0.5348\n",
            "0m 37s (- 1m 1s) (30 37%) 0.3565\n",
            "0m 42s (- 0m 54s) (35 43%) 0.2276\n",
            "0m 48s (- 0m 48s) (40 50%) 0.1422\n",
            "0m 54s (- 0m 42s) (45 56%) 0.0901\n",
            "1m 1s (- 0m 36s) (50 62%) 0.0595\n",
            "1m 6s (- 0m 30s) (55 68%) 0.0412\n",
            "1m 13s (- 0m 24s) (60 75%) 0.0301\n",
            "1m 18s (- 0m 18s) (65 81%) 0.0239\n",
            "1m 24s (- 0m 12s) (70 87%) 0.0200\n",
            "1m 30s (- 0m 6s) (75 93%) 0.0172\n",
            "1m 36s (- 0m 0s) (80 100%) 0.0143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXFRtDu407Ff",
        "outputId": "df558f70-03b4-4bad-9eea-5f08d8b88cb2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> הוא לץ רציני\n",
            "= he is a big prankster\n",
            "< he is a big prankster <EOS>\n",
            "\n",
            "> אני לא מכיר אותו\n",
            "= i am not acquainted with him\n",
            "< i am not acquainted him him theater theater theater theater\n",
            "\n",
            "> הוא לא מתאים להיות מורה\n",
            "= he is unfit to be a teacher\n",
            "< he is unfit to be a teacher <EOS>\n",
            "\n",
            "> הוא בבית היום\n",
            "= he is at home today\n",
            "< he is at home today <EOS>\n",
            "\n",
            "> הביקורת שלו גומזת\n",
            "= he is a harsh critic\n",
            "< he is a harsh critic <EOS>\n",
            "\n",
            "> הוא חסר ניסיון\n",
            "= he is lacking in experience\n",
            "< he is lacking handsome salary salary salary salary salary salary\n",
            "\n",
            "> את תמיד מתלוננת\n",
            "= you are always complaining\n",
            "< you are difficult difficult difficult belt extremely flying flying flying\n",
            "\n",
            "> אני בת אדם\n",
            "= i am human\n",
            "< i am human <EOS>\n",
            "\n",
            "> אני משחק בקבוצת הכדורסל\n",
            "= i am a member of the basketball team\n",
            "< i am a member of the basketball team club help\n",
            "\n",
            "> היא די מרוצה מעבודתה החדשה\n",
            "= she is quite satisfied with her new job\n",
            "< she is quite satisfied with her new job new job\n",
            "\n",
            "> היא אוהבת בעלי חיים\n",
            "= she is fond of animals\n",
            "< she is fond of animals fond of animals fond shadow\n",
            "\n",
            "> הוא עגלגל\n",
            "= he is chubby\n",
            "< he is chubby <EOS>\n",
            "\n",
            "> הוא שוחה בבריכה\n",
            "= he is swimming in the pool\n",
            "< he is swimming in the pool pool pool pool pool\n",
            "\n",
            "> הם תמיד רבים לעיני אנשים\n",
            "= they are always quarrelling in public\n",
            "< they are always quarrelling in some kind need need extremely\n",
            "\n",
            "> הוא מדען דגול\n",
            "= he is a great scientist\n",
            "< he is a great scientist <EOS>\n",
            "\n",
            "> הוא אוכל ארוחת צהריים\n",
            "= he is having lunch\n",
            "< he is having lunch now <EOS>\n",
            "\n",
            "> אני לא מכיר אותו\n",
            "= i am not acquainted with him\n",
            "< i am not acquainted him him theater theater theater theater\n",
            "\n",
            "> היא מדברת\n",
            "= she is talking\n",
            "< she is talking <EOS>\n",
            "\n",
            "> הוא חזק ממני\n",
            "= he is stronger than i am\n",
            "< he is stronger than i am very reserved person salary\n",
            "\n",
            "> הוא לץ רציני\n",
            "= he is a big prankster\n",
            "< he is a big prankster <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "\n",
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    input_labels = [''] + input_sentence.split(' ') + ['']\n",
        "    ax.set_xticks(np.arange(len(input_labels)))\n",
        "    ax.set_yticks(np.arange(len(output_words) + 1))\n",
        "    ax.set_xticklabels(input_labels, rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    display(fig)\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
        "\n",
        "for _ in range(5):\n",
        "    pair = random.choice(pairs)\n",
        "    input_sentence = pair[0]\n",
        "    evaluateAndShowAttention(input_sentence)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iDUZ3mRz0-6J",
        "outputId": "6afe835f-e9f0-4158-d645-688d592cff18"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = הוא בן ארבעים לערך\n",
            "output = he is about forty <EOS>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = הוא בר סמכא בפיזיקה\n",
            "output = he is an authority on physics physics salary <EOS>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = הוא לא לגמרי טועה\n",
            "output = he is not altogether wrong salary salary salary amicably recover\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = הוא אינו רופא אלא מורה\n",
            "output = he is not a doctor but a doctor but a\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = אני מעורה בסוגיה הזו\n",
            "output = i am familiar things familiar him refreshed refreshed refreshed open\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Do you think this model performs well? Why or why not? What are its limitations/disadvantages? What would you do to improve it?  \n"
      ],
      "metadata": {
        "id": "qcqtVxkclIWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model's performance is mixed. Ineed, it can translates some basic sentences reasonably however, it still has significant limitations, especially with longer sentences, it struggles with more complex sentences or words outside of its limited vocabulary and it often makes grammatical errors or produces translations that are not perfectly idiomatic. Also, it produces many errors, ranging from incomplete translations to incorrect words and extra words that do not belong.\n",
        "To improve the model I would moove forward transformers and use Luong Attention.\n",
        "\n"
      ],
      "metadata": {
        "id": "BRqKYze1j0kV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Using any neural network architecture of your liking, build  a model with the aim to beat the model in 2.a. Compare your results in a meaningful way, and add a short explanation to why you think/thought your suggested network is better."
      ],
      "metadata": {
        "id": "i2VSrRNtlJub"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c-tVmomvXcKk"
      },
      "outputs": [],
      "source": [
        "# use the following parameters:\n",
        "MAX_LENGTH = 10\n",
        "hidden_size = 128\n",
        "epochs = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9-C4pLEXzCF"
      },
      "source": [
        "SOLUTION:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 32\n",
        "teacher_forcing_ratio = 0.85\n",
        "beam_width = 5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class LuongAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(LuongAttention, self).__init__()\n",
        "        self.attn = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "\n",
        "    def forward(self, decoder_hidden, encoder_outputs):\n",
        "        scores = torch.bmm(encoder_outputs, decoder_hidden.permute(1, 2, 0))\n",
        "        attn_weights = F.softmax(scores.squeeze(2), dim=1)\n",
        "        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)\n",
        "        return context, attn_weights\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.embedding(input)\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return self.layer_norm(output), hidden\n",
        "\n",
        "class LuongAttnDecoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(LuongAttnDecoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = LuongAttention(hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size * 2, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None, epoch=0):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.full((batch_size, 1), SOS_token, dtype=torch.long, device=device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs, attentions = [], []\n",
        "\n",
        "        use_teacher_forcing = random.random() < (teacher_forcing_ratio - (epoch * 0.015))\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            embedded = self.dropout(self.embedding(decoder_input))\n",
        "            context, attn_weights = self.attention(decoder_hidden, encoder_outputs)\n",
        "            rnn_input = torch.cat((embedded, context), dim=2)\n",
        "            output, decoder_hidden = self.gru(rnn_input, decoder_hidden)\n",
        "            output = self.out(output)\n",
        "            decoder_outputs.append(output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            _, topi = output.topk(1)\n",
        "            decoder_input = target_tensor[:, i].unsqueeze(1) if (target_tensor is not None and use_teacher_forcing) else topi.squeeze(-1).detach()\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "def beam_search(decoder_outputs):\n",
        "    sequences = [[[], 0.0]]\n",
        "    for t in range(MAX_LENGTH):\n",
        "        all_candidates = []\n",
        "        for seq, score in sequences:\n",
        "            probs, topi = decoder_outputs[:, t].topk(beam_width)\n",
        "            for i in range(beam_width):\n",
        "                new_seq = seq + [topi[0][i].item()]\n",
        "                new_score = score + probs[0][i].item()\n",
        "                all_candidates.append((new_seq, new_score))\n",
        "        sequences = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n",
        "    return sequences[0][0]\n",
        "\n",
        "def train(train_dataloader, encoder, decoder, n_epochs=80, learning_rate=0.001, print_every=5):\n",
        "    encoder_optimizer = optim.AdamW(encoder.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    decoder_optimizer = optim.AdamW(decoder.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        total_loss = 0\n",
        "        for input_tensor, target_tensor in train_dataloader:\n",
        "            encoder_optimizer.zero_grad()\n",
        "            decoder_optimizer.zero_grad()\n",
        "\n",
        "            encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "            decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor, epoch)\n",
        "\n",
        "            loss = criterion(decoder_outputs.view(-1, decoder_outputs.size(-1)), target_tensor.view(-1))\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(encoder.parameters(), 5)\n",
        "            torch.nn.utils.clip_grad_norm_(decoder.parameters(), 5)\n",
        "\n",
        "            encoder_optimizer.step()\n",
        "            decoder_optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print(f\"Epoch {epoch}/{n_epochs}, Loss: {total_loss / len(train_dataloader):.4f}\")\n",
        "    print(\"Training Complete!\")\n",
        "\n",
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = torch.LongTensor([input_lang.word2index.get(word, EOS_token) for word in sentence.split(' ')] + [EOS_token]).view(1, -1).to(device)\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        best_sequence = beam_search(decoder_outputs)\n",
        "        decoded_words = [output_lang.index2word[idx] for idx in best_sequence if idx != EOS_token]\n",
        "    return decoded_words, decoder_attn\n",
        "\n",
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "encoder = Encoder(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = LuongAttnDecoder(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train(train_dataloader, encoder, decoder, n_epochs=epochs, print_every=5)\n",
        "evaluateRandomly(encoder, decoder)\n"
      ],
      "metadata": {
        "id": "_WrHkLD6p813",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b574c8-7a3d-41b6-a986-bd35653f2bb8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 128133 sentence pairs\n",
            "Trimmed to 1713 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "heb 2103\n",
            "eng 1278\n",
            "Epoch 5/50, Loss: 2.1906\n",
            "Epoch 10/50, Loss: 1.7990\n",
            "Epoch 15/50, Loss: 1.6251\n",
            "Epoch 20/50, Loss: 1.4376\n",
            "Epoch 25/50, Loss: 1.2027\n",
            "Epoch 30/50, Loss: 0.9926\n",
            "Epoch 35/50, Loss: 0.7477\n",
            "Epoch 40/50, Loss: 0.5417\n",
            "Epoch 45/50, Loss: 0.3691\n",
            "Epoch 50/50, Loss: 0.2382\n",
            "Training Complete!\n",
            "> אני אוהב מכוניות\n",
            "= i am fond of cars\n",
            "< i am fond of playing both SOS SOS SOS\n",
            "\n",
            "> עליך להגיש את העבודות שלך עד יום ב\n",
            "= you are to hand in your assignments by monday\n",
            "< you are saying you to hand your assignments monday monday\n",
            "\n",
            "> אני רעב נורא\n",
            "= i am terribly hungry\n",
            "< i am terribly hungry i did not SOS SOS\n",
            "\n",
            "> אני בן שמונה עשרה\n",
            "= i am eighteen years old\n",
            "< i am eighteen years old SOS SOS SOS SOS\n",
            "\n",
            "> הוא מזדקן\n",
            "= he is getting old\n",
            "< he is not here SOS SOS SOS SOS SOS\n",
            "\n",
            "> הוא נחוש להצליח\n",
            "= he is eager for success\n",
            "< he is eager for success SOS SOS SOS SOS\n",
            "\n",
            "> את שיכורה\n",
            "= you are drunk\n",
            "< you are deceiving right SOS SOS SOS SOS SOS\n",
            "\n",
            "> היא משוכנעת שבנה עדיין בחיים\n",
            "= she is convinced that her son is still alive\n",
            "< she is still her her son alive alive SOS\n",
            "\n",
            "> אני אחראי על הגנתה\n",
            "= i am responsible for her protection\n",
            "< i responsible for her protection SOS SOS SOS SOS\n",
            "\n",
            "> הוא עלול לאחר לבית הספר\n",
            "= he is likely to be late for school\n",
            "< he is not likely in any school\n",
            "\n",
            "> היא בן אדם אמין\n",
            "= she is a reliable person\n",
            "< she is a reliable over person SOS SOS SOS\n",
            "\n",
            "> אינני מורה\n",
            "= i am not a teacher\n",
            "< i am not a teacher teacher SOS SOS SOS\n",
            "\n",
            "> היא יפה כשלגיה\n",
            "= she is as beautiful as snow white\n",
            "< she is as beautiful as snow she SOS SOS\n",
            "\n",
            "> אני פיני אבל אני מדבר גם שבדית\n",
            "= i am finnish but i speak also swedish\n",
            "< i speak also swedish swedish SOS SOS SOS SOS\n",
            "\n",
            "> אתה מתכוון לומר שבכוונה אתה מסווה את יופיך\n",
            "= you are saying you intentionally hide your good looks\n",
            "< you are saying you intentionally hide hide your good looks\n",
            "\n",
            "> אני רווק\n",
            "= i am a bachelor\n",
            "< i am a tall tomorrow SOS SOS SOS SOS\n",
            "\n",
            "> הוא תמיד נותן מתנות לאשתו\n",
            "= he is always giving presents to his wife\n",
            "< always giving presents presents his salary SOS SOS SOS\n",
            "\n",
            "> היא אדם שאפשר לסמוך עליו\n",
            "= she is a reliable person\n",
            "< she is a reliable person SOS SOS SOS SOS\n",
            "\n",
            "> היא חסרת דאגות\n",
            "= she is free from care\n",
            "< she is free from care SOS SOS SOS SOS\n",
            "\n",
            "> היא מאוהבת בו\n",
            "= she is in love with him\n",
            "< she is in love with him SOS SOS SOS\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that using Luong attention has improved our model getting a better translation. I thought about using Luong attention because it is more computationally efficient than Bahdanau."
      ],
      "metadata": {
        "id": "YrV1VY7Bf64J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html /content/NOTEBOOKFILE.ipynb"
      ],
      "metadata": {
        "id": "zVO82Fh4kL12"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}